---
title: "Optimization Algorithms"
author: "Quasar"
date: "2024-06-10"
categories: [Machine Learning]      
image: "image.jpg"
toc: true
toc-depth: 3
---

## Gradient vector

*Definition*. Let $f:\mathbf{R}^n \to \mathbf{R}$ be a scalar-valued function. The gradient vector of $f$ is defined as:

\begin{align*}
\nabla f(\mathbf{x}) = \left[\frac{\partial f}{\partial x_1},\frac{\partial f}{\partial x_2},\ldots,\frac{\partial f}{\partial x_n}\right]
\end{align*}

The graph of the function $f:\mathbf{R}^n \to \mathbf{R}$ is the *hypersurface* in $\mathbf{R}^{n+1}$ given by the equation 