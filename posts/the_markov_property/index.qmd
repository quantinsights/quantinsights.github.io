---
title: "The Markov Property"
author: "Quasar"
date: "2024-07-12"
categories: [Stochastic Calculus]      
image: "image.jpg"
toc: true
toc-depth: 3
---

## The Markov Property for Diffusions

Let's start by exhibiting the Markov property of Brownian motion. To see this, consider $(\mathcal{F}_t,t\geq 0)$, the natural filtration of the Brownian motion $(B_t,t\geq 0)$. Consider $g(B_t)$ for some time $t$ and bounded function $g$. (For example, $g$ could be an indicator function.) Consider also a random variable $W$ that is $\mathcal{F}_s$ measurable for $s < t$. (For example, $W$ could be $B_s$ or $1_{B_s > 0}$.) Let's compute $\mathbb{E}[g(B_t)W]$.

\begin{align*}
\mathbb{E}[g(B_t)W] &= \mathbb{E}[\mathbb{E}[Wg(B_t - B_s + B_s)|\mathcal{F}_s]]
\end{align*}

The random variable $(B_t - B_s)$ follows a $\mathcal{N}(0,t-s)$ distribution. By LOTUS,

\begin{align*}
\mathbb{E}[g(B_t)W] 
&= \int_0^t \mathbb{E}[W g(y + B_s)|\mathcal{F_s}]f_{(B_t - B_s)|B_s}(y) dy\\
&= \{\text{ Using the fact that }B_t - B_s \perp B_s\}\\
&= \int_0^t \mathbb{E}[W g(y + B_s)]f_{(B_t - B_s)}(y)dy\\
&= \int_0^t \mathbb{E}[W g(y + B_s)]\frac{e^{-\frac{y^2}{2(t-s)}}}{\sqrt{2\pi(t-s)}}dy
\end{align*}

By Fubini's theorem, the integral and the expectation operator can be interchanged, and since $W$ is $\mathcal{F}_s$ measurable, it follows from the definition of conditional expectations that:

$$
\begin{align*}
\mathbb{E}[g(B_t)|\mathcal{F}_s] &= \int_0^t g(y + B_s) \frac{e^{-\frac{y^2}{2(t-s)}}}{\sqrt{2\pi(t-s)}}dy
\end{align*}
$$ {#eq-conditional-expectation-of-function-brownian-motion}

We make two important observations. First, the right hand side is a function of $s,t$ and $B_s$ only (and not of the Brownian motion before time s). In particular, we have:

$$
\mathbb{E}[g(B_t)|\mathcal{F}_s] = \mathbb{E}[g(B_t)|B_s]
$$

This holds for any bounded function $g$. In particular, it holds for all indicator functions. This implies that the conditional distribution of $B_t$ given $\mathcal{F}_s$ depends solely on $B_s$, and not on other values before time $s$. Second, the right-hand side is *time-homogenous* in the sense that it depends on the time difference $t-s$. 

We have just shown that Brownian motion is a *time-homogenous Markov process*. 

::: {#def-markov-process}

### Markov process.

Consider a stochastic process $(X_t,t\geq 0)$ and its natural filtration $(\mathcal{F}_t,t\geq 0)$. It is said to be a *Markov process* if and only if for any (bounded) function $g: \mathbb{R} \to \mathbb{R}$, we have:

$$
\mathbb{E}[g(X_t) | \mathcal{F}_s] = \mathbb{E}[g(X_t) | X_s], \quad \forall t \geq 0, \forall s \leq t
$$ {#eq-markov-process}

:::

This implies that $\mathbb{E}[g(X_t)|\mathcal{F}_s]$ is an explicit function of $s$, $t$ and $X_s$. It is said to be *time-homogenous*, if it is a function of $t-s$ and $X_s$. Since the above holds for all bounded $g$, the conditional distribution of $X_t$ given $\mathcal{F}_s$ is the same as the conditional distribution of $X_t$ given $X_s$. 

One way to compute the conditional distribution of $X_t$ given $\mathcal{F}_s$ is to compute the conditional MGF given $\mathcal{F}_s$, that is:

$$
\mathbb{E}[e^{a X_t}|\mathcal{F}_s], \quad a \geq 0
$$ {#eq-conditional-mgf-of-xt}

The process would be Markov, if the conditional MGF is an explicit function of $s$, $t$ and $X_s$. 

::: {#exm-brownian-motion-is-markov}

(Brownian Motion is Markov) Let $(B_t,t\geq 0)$ be a standard brownian motion. Our claim is that the brownian motion is a markov process.
:::

*Proof.*

We have:

\begin{align*}
\mathbb{E}[e^{a B_t}|\mathcal{F}_s] &= \mathbb{E}[e^{a (B_t - B_s + B_s)}|\mathcal{F}_s]\\
& \{ \text{ since }B_s \text{ is }\mathcal{F}_s-\text{ measurable }\}\\
&= e^{a B_s} \mathbb{E}[e^{a (B_t - B_s)}|\mathcal{F}_s]\\
& \{ \text{ since }$B_t - B_s \perp \mathcal{F}_s$ \}\\
&= e^{a B_s} \mathbb{E}[e^{a (B_t - B_s)}]\\
&= e^{a B_s} e^{\frac{1}{2}a^2(t-s)}
\end{align*}

This closes the proof. $\blacksquare$

An equivalent (but more symmetric) way to express the Markov property is to say that *the future of the process is independent of the past, when conditioned on the present*. Concretely, this means that for any $r < s< t$, we have that $X_t$ is independent of $X_r$, when we condition on $X_s$.

The conditional distribution of $X_t$ given $X_s$ is well described using *transition probabilities*. We will more interested in a case well these probabilities admit a density $f_{X_t|X_s=x}(y)$. More precisely, for such a Markov process, we have:

$$
\begin{align*}
\mathbb{E}[g(X_t)|X_s = x] &= \int_{\mathbb{R}} g(y) f_{X_t|X_s=x}(y) dy\\
&=\int_{\mathbb{R}} g(y) p_{s,t}(x,y) dy
\end{align*}
$$

Here, we explicitly write the left-hand side 




