{
  "hash": "0b51dcb9f69e3cf5e27eef9d97b40311",
  "result": {
    "markdown": "---\ntitle: \"Ito Processes and Stochastic Differential Equations\"\nauthor: \"Quasar\"\ndate: \"2024-07-08\"\ncategories: [Stochastic Calculus]      \nimage: \"image.jpg\"\ntoc: true\ntoc-depth: 3\n---\n\n# Ito Processes and Stochastic Differential Equations.\n\nLet's start with the definition of Ito processes.\n\n::: {#def-ito-process}\n### Ito Process\n\nLet $(B(t):t\\geq0)$ be a standard brownian motion defined on $(\\Omega,\\mathcal{F},\\mathbb{P})$. An Ito process $(X(t):t\\geq0)$ is of the form:\n\n\n\n$$\\begin{aligned}\nX(t) & =X(0)+\\int_{0}^{t}V(s)dB(s)+\\int_{0}^{t}D(s)ds\n\\end{aligned}$$ {#eq-ito-process}\n\nwhere $(V(t),t\\geq0)$ and $(D(t),t\\geq0)$ are two adapted processes for\nwhich the integrals make sense in the sense of Ito and Riemann. We refer\nto $(V(t):t\\geq0)$ as the *local volatility* and to $(D(t):t\\geq0)$ as\nthe *local drift*.\n:::\n\nWe will often denote an Ito process $(X(t):t\\geq0)$ in differential form\nas:\n\n$$\\begin{aligned}\ndX(t) & =D(t)dt+V(t)dB(t)\n\\end{aligned}$$ {#eq-ito-process-differential-form}\n\nThis form makes no rigorous sense; when we write it, we mean @eq-ito-process. Nevertheless, the differential equation\nhas two great advantages:\n\n\\(1\\) It gives some intuition on what drives the variation of $X(t)$. On\none hand, there is a contribution of the Brownian increments which are\nmodulated by the volatility $V(t)$. On the other hand, there is a\nsmoother contribution coming from the time variation which is modulated\nby the drift $D(t)$.\n\n\\(2\\) The differential notation has computational power. In particular,\nevaluating Ito's formula is reduced to computing differentials, as in\nclassical calculus, but by doing it upto the second order.\n\nAn important class of Ito processes is given by processes for which the\nvolatility and the drift are simply functions of the position of the\nprocess.\n\n::: {#def-time-homogenous-ito-process}\n\nLet $(B(t):t\\geq0)$ be a standard Brownian motion. An Ito\nprocess $(X(t):t\\geq0)$ of the form\n\n$$\\begin{aligned}\ndX(t) & =\\mu(X(t))dt+\\sigma(X(t))dB(t),\\quad X(0)=x\n\\end{aligned}$$ {#eq-time-homogenous-ito-process}\n\nwhere $\\mu$ and $\\sigma$ are functions from $\\mathbf{R}$ to\n$\\mathbf{R}$, is called a time-homogenous diffusion. \n:::\n\n::: {#def-time-inhomogenous-ito-process}\n\nAn Ito-process $(Y(t),t\\geq0)$ of the form:\n\n$$\\begin{aligned}\n{1}\ndY(t) & =\\mu(t,X(t))dt+\\sigma(t,X(t))dB(t)\\quad Y(0)=y\n\\end{aligned}$$ {#eq-time-inhomogenous-SDE}\n\nwhere $\\mu$ and $\\sigma$ are now functions\n$[0,\\infty)\\times\\mathbf{R}\\to\\mathbf{R}$ is called a time-inhomogenous\ndiffusion.\n:::\n\nThe equations above are called *stochastic differential equations* (SDE) of the respective process $(X(t))$ and $(Y(t))$.\n\nIn other words, a diffusion $(X(t),t\\geq 0)$ is an Ito process\nwhose local volatility $V(t)$ and local drift $D(t)$ at time $t$ depend\nonly on the position of the process at time $t$ and possibly on the time\n$t$ itself. It cannot depend on the path of the process before time $t$\nor on the explicit values of the driving Brownian motion at that time\n(which is not the process $X(t)$ itself). The class of diffusions, and\nof the Ito processes in general, constitutes a huge collection of\nstochastic processes for stochastic modelling.\n\nNote that an SDE is a generalization of ordinary differential equations\nor ODEs. Indeed, if there were no randomness, that is, no Brownian\nmotion, the SDE would be reduced to\n\n$$\\begin{aligned}\ndX(t) & =\\mu(X(t))dt\n\\end{aligned}$$\n\nThis can be written for $X(t)=f(t)$ as:\n\n$$\\begin{aligned}\n\\frac{df}{dt} & =\\mu(f)\n\\end{aligned}$$\n\nThis is a first-order ordinary differential equation. It governs the\ndeterministic evolution of the function $X(t)=f(t)$ in time. An SDE adds\na random term to this evolution that is formally written as:\n\n$$\\begin{aligned}\n\\frac{dX}{dt} & =\\mu(X(t))+\\sigma(X(t))\\frac{dB(t)}{dt}\n\\end{aligned}$$\n\nWe know very well, that Brownian motion is not differentiable; hence the\nabove is not well-defined. The ill-defined term $dB(t)/dt$ is sometimes\ncalled white noise. However, equation @eq-time-homogenous-ito-process is well-defined in the\nsense of the Ito process. These types of equations are well-suited to\nmodel phenomena with intrinsic randomness.\n\nHere are some examples of diffusions:\n\n::: {#exm-brownian-motion-with-a-drift}\n\n(Brownian Motion with a drift). If we take\n$X(t)=\\sigma B(t)+\\mu t$ for some $\\sigma>0$ and $\\mu\\in\\mathbf{R}$,\nthen we can write $X(t)$ as:\n\n$$\\begin{aligned}\nX(t) & =\\int_{0}^{t}\\sigma dB(t)+\\int_{0}^{t}\\mu dt,\\quad X(0)=0\n\\end{aligned}$$\n\nIn the differential form this becomes\n\n$$\\begin{aligned}\ndX(t) & =\\mu dt+\\sigma dB(t)\n\\end{aligned}$$\n\nIn this case, the local drift and the local volatility are constant.\n:::\n\n::: {#exm-geometric-brownian-motion}\n\n(Geometric Brownian Motion). We consider the process\n$S(t)=\\exp((\\mu-\\sigma^{2}/2)t+\\sigma B(t))$. To find the stochastic\ndifferential equation, we apply the Ito's Lemma to\n\n$$\\begin{aligned}\nf(t,x) & =\\exp((\\mu-\\sigma^{2}/2)t+\\sigma x)\n\\end{aligned}$$\n\nWe have:\n\n$$\\begin{aligned}\ndf(t,x) & =\\left((\\mu-\\sigma^{2}/2)+\\frac{1}{2}\\sigma^{2}\\right)\\exp((\\mu-\\sigma^{2}/2)t+\\sigma x)dt+\\sigma\\exp((\\mu-\\sigma^{2}/2)t+\\sigma x)dB(t)\\\\\n & =\\mu S(t)dt+\\sigma S(t)dB(t)\n\\end{aligned}$$\n\nNote that the local drift and the local volatility are now proportional\nto the position. So, the higher $S(t)$, the higher the volatility and\ndrift.\n:::\n\n::: {#exm-smooth-function-of-brownian-motion}\n\n(Any smooth function of Brownian motion). Ito's formula\ngurarantees that any smooth function $f(t,B(t))$ of time and a Brownian\nmotion is an Ito process with volatility $V(t)=\\partial_{t}f(t,B(t))$\nand drift $D(t)=\\partial_{x}f(t,B(t))+\\frac{1}{2}\\partial_{xx}f(t,B(t))$. We will\nsee in further ahead, that, in general, any reasonable function of an\nIto process remains an Ito process.\n\n:::\n\n::: {#exm-ito-process-that-is-not-a-diffusion}\n\n(An Ito process that is not a diffusion) Consider the process\n\n$$\\begin{aligned}\nX(t) & =\\int_{0}^{t}B^{2}(s)dB(s)\n\\end{aligned}$$\n\nThis is an Ito process with local volatility $V(t)=B(t)^{2}$ and local\ndrift $D(t)=0$. However, it is not a diffusion, because the local\nvolatility is not an explicit function of $X(t)$.\n\nIt turns out that the Brownian bridge is a time-inhomogenous diffusion\nand that the Ornstein-Uhlenbeck process is a time-homogenous diffusion.\nTo understand these examples, we need to extend Ito's formula to Ito\nprocesses.\n:::\n\n## Ito's Formula.\n\nThe first step towards a general Ito's formula is the quadratic\nvariation of an Ito process.\n\n::: {#prp-quadratic-variation-of-an-ito-process}\n### Quadratic variation of an Ito process. \n\nLet $(B(t),t\\geq0)$ be a standard Brownian motion and $(X(t):t\\geq0)$ be an Ito process of\nthe form $dX(t)=V(t)dB(t)+D(t)dt$. Then, the quadratic variation of the\nprocess $(X(t):t\\geq0)$ is:*\n\n$$\\begin{aligned}\n<X,X>_{t} & =\\lim_{n\\to\\infty}\\sum_{j=0}^{n-1}(X(t_{j+1})-X(t_{j}))^{2}=\\int_{0}^{t}V(s)^{2}ds\n\\end{aligned}$$ {#eq-quadratic-variation-ito-process}\n\n*for any partition $(t_{j},j\\leq n)$ of $[0,t]$, where the limit is in\nprobability.*\n:::\n\n::: {#rem-remark1}\nNote that the quadratic variation is increasing in $t$, but it is not deterministic in general! $V_t$ is a random variable. The quadratic variation is a smooth stochastic process. (It is differentiable) Observe that we recover the quadratic variation for the Brownian motion for $V(t)=1$ as expected. We also notice that the formula follows easily from the rules of Ito Calculus, thereby showing the consistency of the theory. Indeed we have:\n\n$$\\begin{aligned}\nd<X,X>_{t} & =(dX(t))^{2}=(V(t)dB(t)+D(t)dt)^{2}\\\\\n & =V(t)^{2}(dB(t))^{2}+2V(t)D(t)dB(t)\\cdot dt+D^{2}(t)(dt)^{2}\\\\\n & =V(t)^{2}dt\n\\end{aligned}$$\n:::\n\n::: proof\n*Proof.* The proof is involved, but it reviews some important concepts\nof stochastic calculus. We prove the case when the process $V$ is in\n$\\mathcal{L}_{c}^{2}(T)$ for some $T>0$. We write\n$I(t)=\\int_{0}^{t}V(s)dB(s)$ and $R(t)=\\int_{0}^{t}D(s)ds$. We first\nshow that only the Ito integral contributes to the quadratic variation\nand the Riemann integral does not contribute, so that:\n\n$$\\begin{aligned}\n<X,X>_{t} & =<I,I>_{t}\n\\end{aligned}$$ {#eq-quadratic-variation-ito-process-ii}\n\nWe have that the increment square of $X(t)$ is:\n\n$$\\begin{aligned}\n(X(t_{j+1})-X(t_{j}))^{2} & =(I(t_{j+1})-I(t_{j}))^{2}+2(I(t_{j+1})-I(t_{j}))(R(t_{j+1})-R(t_{j}))+(R(t_{j+1})-R(t_{j}))^{2}\n\\end{aligned}$$\n\nThe Cauchy-Schwarz inequality implies :\n\n$$\\begin{aligned}\n\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))(R(t_{j+1})-R(t_{j})) & \\leq\\left(\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}\\right)^{1/2}\\left(\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))^{2}\\right)^{1/2}\n\\end{aligned}$$\n\nTherefore, to prove equation @eq-quadratic-variation-ito-process, it suffices to show that $\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))^{2}\\to 0$ almost surely. Since $D(s)$ is an almost surely continuous process, the stochastic process $R(t)=\\int_{0}^{t}D(s)ds$ has continuous paths with probability $1$. Therefore:\n\n$$\\begin{aligned}\n\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))^{2} & =\\max_{1\\leq j\\leq n}|R(t_{j+1})-R(t_{j})|\\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))\n\\end{aligned}$$\n\nSince, $R(t)$ is continuous on the compact set $[0,t]$, it is uniformly\ncontinuous a.s. So, as $|t_{j+1}-t_{j}|\\to 0$, by uniform continuity it\nfollows that $\\max|R(t_{j+1})-R(t_{j})|\\to 0$ a.s.\n\nIt remains to prove that $<I,I>_{t}=\\int_{0}^{t}V(s)^{2}ds$. We first\nprove the case when $V\\in\\mathcal{S}(T)$ is a simple adapted process.\nConsider a partition $(t_{j}:j\\leq n)$ of $[0,t]$. Without loss of\ngenerality, we can suppose that $V$ is constant on each\n$[t_{j},t_{j+1})$ by refining the partition. We then have:\n\n$$\\begin{aligned}\n\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2} & =\\sum_{j=0}^{n-1}V(t_{j})^{2}(B(t_{j+1})-B(t_{j}))^{2}\n\\end{aligned}$$\n\nNow, we have seen in the proof of Ito's formula that $\\mathbb{E}\\left[\\left\\{ \\sum_{j=0}^{n-1}V(t_{j})^{2}((B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})\\right\\} ^{2}\\right]\\to 0$, so $\\sum_{j=0}^{n-1}V(t_{j})^{2}(B(t_{j+1})-B(t_{j}))^{2}$ approaches $\\sum_{j=0}^{n-1}V(t_{j})^{2}(t_{j+1}-t_{j})$ in the mean square sense. As the mesh size becomes finer, the $L^{2}$-limit is $\\int_{0}^{t}V(t)^{2}dt$.\n\nThe case $V\\in\\mathcal{L}_{c}^{2}(T)$ is proved by approximating $V$ by a simple process in $\\mathcal{S}(T)$. More precisely, we can find a simple process $V^{(\\epsilon)}(t)$ that is $\\epsilon$-close to $V$ in the sense:\n\n$$\\begin{aligned}\n||I^{(\\epsilon)}-I|| & =||\\int V^{\\epsilon}dB(t)-\\int VdB(t)||=\\int_{0}^{t}\\mathbb{E}[(V^{(\\epsilon)}(t)-V(t))^{2}]ds<\\epsilon\n\\end{aligned}$$ {#eq-sequence-of-simple-processes}\n\nTo prove the claim, we need to show that for $t\\leq T$,\n\n$$\\begin{aligned}\n\\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-\\int_{0}^{t}(V(s))^{2}ds\\right|\\right] & \\to0\\quad\\text{as }\\quad n\\to\\infty\n\\end{aligned}$$\n\n$L^{1}$-convergence implies convergence in probability of the sequence\n$\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}$. We now introduce the\n$V^{(\\epsilon)}(t)$ approximation inside the absolute value as well as\nits corresponding integral\n$I^{(\\epsilon)}(t)=\\int_{0}^{t}V^{(\\epsilon)}(s)ds$. By the triangle\ninequality, we have:\n\n$$\\begin{aligned}\n & \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-\\int_{0}^{t}(V(s))^{2}ds\\right|\\right]\\nonumber \\\\\n= & \\mathbb{E}\\left[\\Biggl|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}+(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}-\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds\\right.\\nonumber \\\\\n & +\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds-\\int_{0}^{t}(V(s))^{2}ds\\Biggr|\\Biggr]\\nonumber \\\\\n\\leq & \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}\\right|\\right]+\\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}(I^{(\\epsilon)}(t_{j+1})-I^{(\\epsilon)}(t_{j}))^{2}-\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds\\right|\\right]\\\\\n & +\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds-\\int_{0}^{t}(V(s))^{2}ds\\Biggr|\\right]\\nonumber \n\\end{aligned}$$ {#eq-quadratic-variation-of-ito-process-i}\n\nWe show that the first and third terms converge uniformly and that the second term goes to $0$ as $n\\to\\infty$.\n\nThe second term goes to $0$ as $n\\to\\infty$ by the argument for simple\nprocesses.\n\n$<I^{(\\epsilon)},I^{(\\epsilon)}>_{t}=\\int_{0}^{t}V^{(\\epsilon)}(s)^{2}ds$.\n\nFor the third term, the linearity of the integral and the Cauchy Schwarz inequality (applied to $\\mathbb{E}\\int_{0}^{t}$) imply that it is:\n\n$$\\begin{aligned}\n\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s))^{2}ds-\\int_{0}^{t}(V(s))^{2}ds\\Biggr|\\right] & \\leq\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s)-V(s))^{2}ds\\Biggr|\\right]^{1/2}\\mathbb{E}\\left[\\Biggl|\\int_{0}^{t}(V^{(\\epsilon)}(s)+V(s))^{2}ds\\Biggr|\\right]^{1/2}\n\\end{aligned}$$\n\nThe first factor is smaller than the square root of $\\epsilon$ by @eq-sequence-of-simple-processes, whereas the second factor is bounded.\n\nThe first term in equation @eq-quadratic-variation-of-ito-process-i is handled similarly. The linearity of the Ito integral and the Cauchy-Schwarz inequality applied to $\\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}\\cdot\\right)\\right]$ give that the first term is:\n\n$$\\begin{aligned}\n & \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}(V(s))^{2}dB(s)-\\int_{t_{j}}^{t_{j+1}}(V^{\\epsilon}(s))^{2}dB(s)\\right|\\right]\\\\\n= & \\mathbb{E}\\left[\\left|\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\int_{t_{j}}^{t_{j+1}}(V(s)+V^{\\epsilon}(s))dB(s)\\right|\\right]\\\\\n\\leq & \\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\right)^{2}\\right]^{1/2}\\mathbb{E}\\left[\\Biggl|\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)+V^{\\epsilon}(s))dB(s)\\right)^{2}\\Biggr|\\right]^{1/2}\n\\end{aligned}$$\n\nBy Ito isometry, the first factor in the above expression can be\nsimplified:\n\n$$\\begin{aligned}\n\\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\right)^{2}\\right]^{1/2} & =\\sum_{j=0}^{n-1}\\mathbb{E}\\left(\\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\\epsilon}(s))dB(s)\\right)^{2}\\\\\n & =\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}\\mathbb{E}[(V(s)-V^{\\epsilon}(s))^{2}]ds\n\\end{aligned}$$\n\nBy @eq-sequence-of-simple-processes, this factor is smaller than $\\epsilon$. The second factor equals\n$\\sum_{j=0}^{n-1}\\int_{t_{j}}^{t_{j+1}}\\mathbb{E}[(V(s)+V^{\\epsilon}(s))^{2}]ds$ by Ito-isometry and is uniformly bounded. This concludes the proof of\nthe proposition. $\\blacksquare$\n:::\n\nNote that quadratic variation $<I,I>_{t}=\\int(V(s))^{2}ds$ is computed\npath-by-path and hence the result is random. On the other the variance\nof the Ito integral $Var(I(t))=\\mathbb{E}[I_{t}^{2}]=\\int\\mathbb{E}[V_{s}^{2}]ds$ is the\nmean value of all possible paths of the quadratic variation and hence is\nnon-random. We are now ready to state Ito's formula for Ito processes.\nWe write the result in differential form for conciseness.\n\n::: {#thm-ito-formula-for-ito-processes}\n\n### Ito's formula for Ito processes \n\nLet $(B(t):t\\geq0)$ be a standard brownian motion, and let $(X(t):t\\geq0)$ be an Ito process of\nthe form $dX(t)=V(t)dB(t)+D(t)dt$. Consider a function\n$f(t,x)\\in\\mathcal{C}^{1,2}([0,T]\\times\\mathbf{R})$. Then we have with\nprobability one for all $t\\leq T$:*\n\n*$$\\begin{aligned}\ndf(t,X(t)) & =\\partial_{x}f(t,X(t))dX(t)+\\partial_{t}f(t,X(t))dt+\\frac{1}{2}\\partial_{xx}f(t,X(t))d<X,X>_{t}\n\\end{aligned}$$*\n\n*This can also be written as:*\n\n*$$\\begin{aligned}\ndf(t,X(t))= & \\partial_{x}f(t,X(t))V(t)dB(t)+\\left[\\partial_{x}f(t,X(t))D(t)+\\partial_{t}f(t,X(t))+\\frac{1}{2}(V(t))^{2}\\partial_{xx}f(t,X(t))\\right]dt\n\\end{aligned}$$*\n:::\n\nThe proof of the @thm-ito-formula-for-ito-processes is again a Taylor approximation with the form of the quadratic variation of the process.\nWe will omit it.\n\n::: {#exm-ornstein-uhlenbeck-process}\n\n(Ornstein-Uhlenbeck Process). Consider the Ornstein-Uhlenbeck process $(Y(t):t\\geq0)$:\n\n$$\\begin{aligned}\nY(t) & =Y(0)e^{-t}+e^{-t}\\int_{0}^{t}e^{s}dB(s)\n\\end{aligned}$$\n\nNote that this process is an explicit function of $t$ and of the Ito\nprocess $X(t)=Y(0)+\\int_{0}^{t}e^{s}dB(s)$. Indeed, we have:\n\n$$\\begin{aligned}\nY(t) & =e^{-t}X(t)\n\\end{aligned}$$\n\nLet $f(t,x)=e^{-t}x$. Then, $f_{x}(t,x)=e^{-t}$, $f_{xx}(t,x)=0$ and\n$f_{t}(t,x)=-e^{-t}x$. So, by Ito's lemma,\n\n$$\\begin{aligned}\ndf(t,x) & =f_{t}(t,X(t))dt+f_{x}(t,X(t))dX(t)+\\frac{1}{2}f_{xx}(t,X(t))d<X,X>_{t}\\nonumber \\\\\ndY(t) & =-Y(t)dt+e^{-t}dX(t)\\nonumber \\\\\ndY(t) & =-Y(t)dt+e^{-t}(e^{t}dB(t))\\nonumber \\\\\ndY(t) & =-Y(t)dt+dB(t)\n\\end{aligned}$$ {#eq-ornstein-uhlenbeck-sde}\n\nThis is the SDE for the Ornstein Uhlenbeck process.\n\nThe SDE has a very nice interpretation: The drift is positive if\n$Y(t)<0$ and negative if $Y(t)>0$. Moreover, the drift is proportional\nto the position (exactly like a spring pulling the process back to the\n$x$-axis following the Hooke's law!). This is the mechanism that ensures\nthat the process does not venture too far from $0$ and is eventually\nstationary.\n\nThe SDE @eq-ornstein-uhlenbeck-sde is now easily generalized by adding two parameters for the volatility and the drift:\n\n$$\\begin{aligned}\ndY(t) & =-kY(t)dt+\\sigma dB(t),\\quad k\\in\\mathbf{R},\\sigma>0\n\\end{aligned}$$ {#eq-ornstein-uhlenbeck-sde-ii}\n\nIt is not hard to check that the solution to the SDE is:\n\n$$\\begin{aligned}\nY(t) & =Y(0)e^{-kt}+e^{-kt}\\int_{0}^{t}e^{ks}\\sigma dB(s)\n\\end{aligned}$$ {#eq-solution-to-the-ornstein-uhlenbeck-sde}\n:::\n\n::: {#exr-the-ornstein-uhlenbeck-process-with-parameters}\n\nThe Ornstein-Uhlenbeck process with parameters. Use the Ito's formula to show that the @eq-solution-to-the-ornstein-uhlenbeck-sde is the solution\nto the Ornstein-Uhlenbeck SDE @eq-ornstein-uhlenbeck-sde-ii.\n:::\n\n*Solution.*\n\nLet $X(t)=Y(0)+\\int_{0}^{t}e^{ks}\\sigma dB(s)$, so\n$dX(t)=e^{kt}\\sigma dB(t)$. Then, $Y(t)=e^{-kt}X(t)$. Let\n$f(t,x)=e^{-kt}x$. Then, by Ito's formula:  \n\n$$\\begin{aligned}\ndf(t,x) & =-ke^{-kt}X(t)dt+e^{-kt}dX(t)\\\\\ndY(t) & =-kY(t)dt+e^{-kt}e^{kt}\\sigma dB(t)\\\\\ndY(t) & =-kY(t)dt+\\sigma dB(t)\n\\end{aligned}$$\n\nThe latest version of Ito's formula is another useful tool for producing\nmartingales from a function of an Ito process. We start with two\nexamples generalizing martingales for Brownian motion.\n\n::: {#exm-generalization-of-bt2-t}\n\n(A generalization of $(B(t))^{2}-t$). Let $(V(t):t\\leq T)$ be a\nprocess in $\\mathcal{L}_{c}^{2}(T)$. Consider an Ito process\n$(X(t):t\\leq T)$ given by $dX(t)=V(t)dB(t)$. Note that\n$((X(t))^{2}:t\\leq T)$ is a submartingale by Jensen's inequality, since\n$\\mathbb{E}[X^{2}(t)|\\mathcal{F}_{s}]\\geq(\\mathbb{E}[X(t)|\\mathcal{F}_{s})^{2}=X^{2}(s)$.\nWe show that the compensated process\n\n$$\\begin{aligned}\nM(t) & =X^{2}(t)-\\int_{0}^{t}V^{2}(s)ds,\\quad t\\leq T\n\\end{aligned}$$\n\nis a martingale for the Brownian filtration. (This is another instance\nof the Doob-Meyer decomposition). By the Ito's formula for $f(x)=x^{2}$,\nwe have:\n\n$$\\begin{aligned}\ndf(x) & =f_{x}(X(t)dX(t)+\\frac{1}{2}f_{xx}(X(t))d<X,X>_{t}\\\\\n & =2X(t)dX(t)+(V(t))^{2}dt\\\\\ndf(X(t)) & =2X(t)V(t)dB(t)+(V(t))^{2}dt\n\\end{aligned}$$\n\nIn Integral form this implies:\n\n$$\\begin{aligned}\n(X(t))^{2} & =(X(0))^{2}+2\\int_{0}^{t}X(s)V(s)dB(s)+\\int_{0}^{t}(V(s))^{2}ds\\\\\nM(t)=(X(t))^{2}-\\int_{0}^{t}(V(s))^{2}ds & =(X(0))^{2}+2\\int_{0}^{t}X(s)V(s)dB(s)\n\\end{aligned}$$\n\nWe conclude that $(M(t):t\\leq T)$ is a martingale, provided\n$X(t)V(t)\\in L_{c}^{2}(T)$.\n\nThere is another more direct way to prove that $(M(t):t\\leq T)$ is a\nmartingale whenever $(V(t):t\\leq T)\\in\\mathcal{L}_{c}^{2}(T)$. This is\nby using increments: for $t'<t\\leq T$,\n\n$$\\begin{aligned}\n\\mathbb{E}[X_{t'}^{2}|\\mathcal{F}_{t}] & =\\mathbb{E}[(X_{t}+(X_{t'}-X_{t}))^{2}|\\mathcal{F}_{t}]\\\\\n & =\\mathbb{E}[X_{t}^{2}+2X_{t}(X_{t'}-X_{t})+(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}]\\\\\n & =X_{t}^{2}+2X_{t}\\mathbb{E}[X_{t'}-X_{t}|\\mathcal{F}_{t}]+\\mathbb{E}[(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}]\n\\end{aligned}$$\n\nSince $(X_{t}:t\\geq0)$ is a martingale,\n$\\mathbb{E}[(X_{t'}-X_{t})|M_{t}]=0$, so the middle term equals zero and\nwe are left with:\n\n$$\\begin{aligned}\n\\mathbb{E}[X_{t'}^{2}|\\mathcal{F}_{t}] & =X_{t}^{2}+\\mathbb{E}[(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}]\n\\end{aligned}$$\n\nBy conditional Ito Isometry,\n\n$$\\begin{aligned}\n\\mathbb{E}[(X_{t'}-X_{t})^{2}|\\mathcal{F}_{t}] & =\\int_{0}^{t'}V_{s}^{2}ds-\\int_{0}^{t}V_{s}^{2}ds=\\int_{t}^{t'}V_{s}^{2}ds\n\\end{aligned}$$\n:::\n\n::: {#exm-generalization-of-gbm} \n\n(A generalization of the geometric Brownian motion). Let\n$\\sigma(t)$ be a continuous, deterministic function such that\n$|\\sigma(t)|\\leq1$, $t\\in[0,T]$. The process\n\n$$\\begin{aligned}\nM(t) & =\\exp\\left(\\int_{0}^{t}\\sigma(s)dB(s)-\\frac{1}{2}\\int_{0}^{t}\\sigma^{2}(s)ds\\right),\\quad t\\leq T\n\\end{aligned}$$\n\nis a martingale for the Brownian filtration. To see this, note that we\ncan write $M(t)=f(t,X(t))$ where\n$f(t,x)=\\exp(x-\\frac{1}{2}\\int\\sigma^{2}(s)ds)$ and\n$X(t)=\\int_{0}^{t}\\sigma(s)dB(s)$, so $dX(t)=\\sigma(t)dB(t)$. Ito's\nformula gives:\n\n$$\\begin{aligned}\ndf(t,x) & =f_{t}(t,X(t)dt+f_{x}(t,X(t))dX(t)+\\frac{1}{2}f_{xx}(t,X(t))d<X,X>_{t}\\\\\ndM(t) & =-\\frac{1}{2}\\sigma^{2}(t)M(t)dt+M(t)\\sigma(t)dB(t)+\\frac{1}{2}M(t)\\sigma^{2}(t)dt\\\\\n & =M(t)\\sigma(t)dB(t)\\\\\nM(t) & =M(0)+\\int_{0}^{t}M(s)\\sigma(s)dB(s)\n\\end{aligned}$$\n\nObserve also that:\n\n$$\\begin{aligned}\n\\mathbb{E}[M_{t}^{2}] & =e^{-\\int_{0}^{t}\\sigma^{2}(s)ds}\\mathbb{E}[e^{2\\int_{0}^{t}\\sigma(s)dB(s)}]=e^{\\int_{0}^{t}\\sigma^{2}(s)ds}\n\\end{aligned}$$\n\nsince $\\int_{0}^{t}\\sigma(s)dB(s)$ is a Gaussian random variable with\nmean $0$ and variance $\\int_{0}^{t}\\sigma^{2}(s)ds$.\n\nWe conclude from the equation that $(M(t),t\\geq0)$ is a martingale.\n:::\n\n::: {#exm-martingales-of-gbm}\n\n(Martingales of Geometric Brownian Motion). Let\n\n$$\\begin{aligned}\nS(t) & =S(0)\\exp(\\sigma B(t)-\\sigma^{2}t/2)\n\\end{aligned}$$\n\nbe a geometric brownian motion. We find a PDE satisfied by $f(t,x)$ for\n$f(t,S(t))$ to be a martingale. It suffices to apply Ito's formula of @thm-ito-formula-for-ito-processes. We get:\n\n$$\\begin{aligned}\ndf(t,S(t)) & =f_{t}(t,S(t))dt+f_{x}(t,S(t))dS(t)+\\frac{1}{2}f_{xx}(t,S(t))dS(t)\\cdot dS(t)\n\\end{aligned}$$\n\nNow note from the earlier result that $dS(t)=S(t)\\sigma dB(t)$. So,\n$dS(t)\\cdot dS(t)=\\frac{1}{2}\\sigma^{2}(S(t))^{2}dt$. So,\n\n$$\\begin{aligned}\ndf(t,S(t)) & =\\left\\{ \\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\sigma^{2}(S(t))^{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right\\} dt+\\sigma S(t)\\frac{\\partial f}{\\partial x}dB(t)\n\\end{aligned}$$\n\nFinally, the PDE for $f(t,x)$ is obtained by setting the factor in front\nof $dt$ to $0$, because we want $f$ to be a martingale process. It is\nimportant to keep in mind, that the PDE should always be written in\nterms of the time variable $t$ and the space variable $x$. Therefore,\nthe PDE of $f$ as a function of time and space is:\n\n$$\\begin{aligned}\n\\frac{1}{2}\\sigma^{2}x^{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(t,x)+\\frac{\\partial f}{\\partial t}(t,x) & =0\n\\end{aligned}$$\n\nNo more randomness appears in the PDE!\n:::\n\nHere is a specific case where we can apply the Ito's formula to\nconstruct martingales of Ito processes.\n\n::: {#exm-martingale-1}\n\nConsider the process given by the SDE:\n\n$$\\begin{aligned}\ndX(t) & =X(t)dB(t),\\quad X(0)=2\n\\end{aligned}$$\n\nLet's find a PDE for which $f(t,X(t))$ is a martingale for the Brownian\nfiltration. We have by Ito's formula that:\n\n$$\\begin{aligned}\ndf(t,X(t)) & =f_{t}(t,X(t))dt+f_{x}(t,X(t))dX(t)+\\frac{1}{2}f_{xx}(t,X(t))d<X,X>_{t}\\\\\n & =\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}(X(t))^{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)dt+X(t)\\frac{\\partial f}{\\partial x}dB(t)\n\\end{aligned}$$\n\nSetting the drift term to $0$ gives the PDE:\n\n$$\\begin{aligned}\n\\frac{\\partial f}{\\partial t}+\\frac{1}{2}x^{2}\\frac{\\partial^{2}f}{\\partial x^{2}} & =0\n\\end{aligned}$$\n\nIt is then easy to check that $X(t)$ is a martingale and so is\n$t+\\log(X(t))^{2}$, since the functions $f(t,x)=x$ and\n$f(t,x)=t+\\log x^{2}$ satisfy the PDE. However, the process $tX(t)$ is\nnot, as the function $f(t,x)=xt$ is not a solution of the PDE.\n:::\n\n## Multivariate Extension.\n\nIto's formula can be generalized to several Ito processes. Let's start\nby stating an example of a function of two Ito processes. Such a\nfunction $f(x_{1},x_{2})$ will be a function of two space variables. Not\nsurprisingly, it needs to have two derivatives in each variable and they\nneed to be a continuous function; we need\n$f\\in\\mathcal{C}^{2\\times2}(\\mathbf{R}\\times\\mathbf{R})$.\n\n::: {#thm-ito-formula-for-many-ito-processes}\n\n### Ito's formula for many Ito processes \n\nLet $(X(t):t\\geq0)$ and (Y(t):t\\geq0)$ be two Ito processes of the form:\n\n$$\\begin{aligned}\ndX(t) & =V(t)dB(t)+D(t)dt\\nonumber \\\\\ndY(t) & =U(t)dB(t)+R(t)dt\n\\end{aligned}$$ {#eq-two-ito-processes}\n\nwhere $(B(t):t\\geq0)$ is a standard Brownian motion. Then, for\n$f\\in\\mathcal{C}^{2\\times2}(\\mathbf{R}\\times\\mathbf{R})$, we have:\n\n$$\\begin{aligned}\ndf(X(t),Y(t)) & =f_{x}(X(t),Y(t))dX(t)+f_{y}(X(t),Y(t))dY(t)+\\frac{1}{2}f_{xx}(X(t),Y(t))d<X,X>_{t}\\\\\n & +f_{xy}(X(t),Y(t))d<X,Y>_{t}+\\frac{1}{2}f_{yy}(X(t),Y(t))d<Y,Y>_{t}\n\\end{aligned}$$\n:::\n\nThe idea of the proof is the same as in @thm-ito-formula-for-ito-processes : Taylor's expansion and\nquadratic variation, together with the cross-variation of two processes.\n\n$$\\begin{aligned}\ndX(t)\\cdot dY(t) & =(V(t)dB(t)+D(t)dt)(U(t)dB(t)+R(t)dt)\\\\\n & =U(t)V(t)dt\n\\end{aligned}$$\n\n::: {#exm-product-rule}\n\n(Product Rule) An important example of this formula is Ito's\nproduct rule. Let $X(t)$ and $Y(t)$ be as in @eq-two-ito-processes. Then:\n\n$$\\begin{aligned}\nd(X(t)Y(t)) & =Y(t)dX(t)+X(t)dY(t)+dX(t)\\cdot dY(t)\n\\end{aligned}$$\n:::\n\n::: {#exr-a-riemann-integral}\nLet $(\\Omega,\\mathcal{F},\\mathbb{P})$ be a probability space\nand let $(B_{t}:t\\geq0)$ be a standard brownian motion. Using\nintegration by parts, show that\n\n$$\\begin{aligned}\n\\int_{0}^{t}B(s)ds & =\\int_{0}^{t}(t-s)dB(s)\n\\end{aligned}$$\n\nand prove that $\\int_{0}^{t}B(s)ds\\sim\\mathcal{N}(0,t^{3}/3)$.\n\nIs\n\n$$\\begin{aligned}\nX(t) & =\\begin{cases}\n0 & t=0\\\\\n\\frac{\\sqrt{3}}{t}\\int_{0}^{t}B(s)ds & t>0\n\\end{cases}\n\\end{aligned}$$\n\na standard Wiener process?\n\n*Solution.*\n\nClearly, $B(s,\\omega)$ is a random variable and the Riemann integral $\\int_0^t B(s,\\omega)ds$ depends on the sample path $\\omega$. So, $(\\int_0^t B_s ds, t\\leq T)$ is a stochastic process. Using integration by parts:\n\n$$\\begin{aligned}\n\\int u\\left(\\frac{dv}{ds}\\right)ds & =uv-\\int v\\left(\\frac{du}{ds}\\right)ds\n\\end{aligned}$$\n\nWe set $u=B(s)$ and $dv/ds=1$. Then:\n\n$$\\begin{aligned}\n\\int_{0}^{t}B(s)ds & =sB(s)|_{0}^{t}-\\int_{0}^{t}sdB(s)\\\\\n & =tB(t)-\\int_{0}^{t}sdB(s)\\\\\n & =\\int_{s=0}^{s=t}tdB(s)-\\int_{0}^{t}sdB(s)\\\\\n & =\\int_{0}^{t}(t-s)dB(s)\n\\end{aligned}$$\n\nThus, $\\int_{0}^{t}B(s)ds$ is a Gaussian random variable with:\n\n$$\\begin{aligned}\n\\mathbb{E}\\left[\\int_{0}^{t}B(s)ds\\right] & =\\mathbb{E}\\left[\\int_{0}^{t}(t-s)dB(s)\\right]\\\\\n & =0\n\\end{aligned}$$\n\nand\n\n$$\\begin{aligned}\n\\mathbb{E}\\left[\\left(\\int_{0}^{t}B(s)ds\\right)^{2}\\right] & =\\int_{0}^{t}(t-s)^{2}ds\\\\\n & =\\left.\\frac{(t-s)^{3}}{-3}\\right|_{0}^{t}\\\\\n & =\\frac{t^{3}}{3}\n\\end{aligned}$$\n\nThus, using the properties of Ito Integral,\n$\\int_{0}^{t}B(s)ds=\\int_{0}^{t}(t-s)dB(s)$ is a martingale. Now the\nquadratic variation $<M,M>_{t}=0$, and this can be a bit tricky.\nRemember,\n$\\left\\langle \\int_{0}^{t}f(s,B_{s})dB(s),\\int_{0}^{t}f(s,B_{s})dB(s)\\right\\rangle =\\int_{0}^{t}f^{2}(s,B_{s})ds$\nif and only if $f$ is a function of the time $s$ and the position of the\nBrownian motion $B(s)$. Since, $f$ is a function of $t$ as well, this\nrule cannot be applied.\n\nBy first principles, we can show that, the quadratic variation is indeed\n$0$: $$\\begin{aligned}\n\\lim_{n\\to\\infty}\\mathbb{E}\\left[\\sum_{j=0}^{n-1}\\left(I(t_{j+1})-I(t_{j})\\right)^{2}\\right] & =\\lim_{n\\to\\infty}\\mathbb{E}\\left[\\sum_{j=0}^{n-1}B_{t_{j}}^{2}(t_{j+1}-t_{j})^{2}\\right]\\\\\n & =\\lim_{n\\to\\infty}\\max_{1\\leq j\\leq n}|t_{j+1}-t_{j}|\\cdot\\mathbb{E}\\left[\\sum_{j=0}^{n-1}B_{t_{j}}^{2}(t_{j+1}-t_{j})\\right]\n\\end{aligned}$$\n\nSince the paths of $B_{t}$ are continuous, so are the paths $B_{t}^{2}$\non the compact interval $[0,t]$. So, $(B_{s}^{2},s\\in[0,t])$ is\nuniformly bounded. Thus, the expectation term is bounded. As\n$n\\to\\infty$, the mesh size approaches zero, and consequently the\nquadratic variation approaches zero.\n:::\n\n::: {#exm-something-that-is-not-a-martingale}\nLet $X_{t}=\\int_{0}^{t}B_{s}dB_{s}$ and\n$Y_{t}=\\int_{0}^{t}B_{s}^{2}dB_{s}$. Is $(X_{t}Y_{t},t\\geq0)$ a\nmartingale?\n:::\n\n*Solution.*\n\nBy Ito's product rule, we have:\n\n$$\\begin{aligned}\nd(X_{t}Y_{t}) & =X_{t}dY_{t}+Y_{t}dX_{t}+dX_{t}\\cdot dY_{t}\\\\\n & =X_{t}B_{s}^{2}dB_{s}+Y_{t}B_{s}dB_{s}+(B_{s}dB_{s})\\cdot(B_{s}^{2}dB_{s})\\\\\n & =X_{t}B_{s}^{2}dB_{s}+Y_{t}B_{s}dB_{s}+B_{s}^{3}dt\\\\\nX_{t}Y_{t} & =X_{0}Y_{0}+\\int_{0}^{t}X_{t}B_{s}^{2}dB_{s}+\\int_{0}^{t}Y_{t}B_{s}dB_{s}+\\int_{0}^{t}B_{s}^{3}dt\n\\end{aligned}$$\n\nThe term in $dt$ is not zero, so the product cannot be a martingale.\n\n::: {#exm-generalization-of-gbm-ii}\n\n(A generalization of Geometric Brownian Motion). Consider $(\\int_{0}^{t}V_{s}dB_{s},t\\geq0)$ an Ito process. Define the positive\nprocess:\n\n$$\\begin{aligned}\nM_{t} & =\\exp\\left(\\int_{0}^{t}V_{s}dB_{s}-\\frac{1}{2}\\int_{0}^{t}V_{s}^{2}ds\\right),\\quad t\\geq0\n\\end{aligned}$$ {#eq-generalization-of-gbm}\n:::\n\n*Solution.*\n\nIto's formula applied to the processes $X_{t}=\\int_{0}^{t}V_{s}dB_{s}$\nand $Y_{t}=\\frac{1}{2}\\int_{0}^{t}V_{s}^{2}ds$ with the function\n$f(x,y)=e^{x-y}$ yields:\n\n$$\\begin{aligned}\ndf(x,y) & =f_{x}(X_{t},Y_{t})dX_{t}+f_{y}(X_{t},Y_{t})dY_{t}\\\\\n & +\\frac{1}{2}f_{xx}(X_{t},Y_{t})dX_{t}\\cdot dX_{t}+\\frac{1}{2}f_{yy}(X_{t},Y_{t})dY_{t}\\cdot dY_{t}\\\\\n & +f_{xy}(X_{t},Y_{t})dX_{t}\\cdot dY_{t}\n\\end{aligned}$$\n\nNow, all first and second order derivatives are\n$\\partial_{x}(e^{x-y})=M_{t}$, $\\partial_{y}(e^{x-y})=-e^{x-y}=-M_{t}$, $\\partial_{xx}(e^{x-y})=M_{t}$\n\n$dX_{t}=V_{t}dB_{t}$. $dY_{t}=\\frac{1}{2}V_{t}^{2}dt$.\n\n$dX_{t}\\cdot dX_{t}=V_{t}^{2}dt$, $dX_{t}\\cdot dY_{t}=0$,\n\n$dY_{t}\\cdot dY_{t}=0$. \n\nConsequently, we have:\n\n$$\\begin{aligned}\ndM_{t} & =M_{t}V_{t}dB_{t}-\\frac{1}{2}M_{t}V_{t}^{2}dt\\\\\n & +\\frac{1}{2}M_{t}V_{t}^{2}dt\\\\\n & =M_{t}V_{t}dB_{t}\n\\end{aligned}$$\n\nThus, $(M_{t},t\\geq0)$ is a martingale.\n\n::: {#exr-generalized-ito-integral}\n\n(Generalized Ito Integral). Let $(\\Omega,\\mathcal{F},\\mathbb{P})$ be a probability space and let\n$(B_{t}:t\\geq0)$ be a standard brownian motion. Given that $f$ is a\nsimple process, show that:\n\n$$\\begin{aligned}\n\\int_{0}^{t}f(s,B_{s})dB_{s} & =B_{t}f(t,B_{t})-\\int_{0}^{t}\\left[B_{s}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}B_{s}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right]ds\\\\\n & -\\int_{0}^{t}B_{s}\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}$$\n\nand\n\n$$\\begin{aligned}\n\\int_{0}^{t}f(s,B_{s})ds & =tf(t,B_{t})-\\int_{0}^{t}s\\left[\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right]ds-\\int_{0}^{t}s\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}$$\n:::\n\n*Solution.*\n\nI suppress $(t,B_{t})$ for simplicity. Applying the product rule to\n$B_{t}f$, we get:\n\n$$\\begin{aligned}\nd(B_{t}f) & =fdB_{t}+B_{t}df+dB_{t}\\cdot df\\\\\n & =fdB_{t}+B_{t}\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n & +dB_{t}\\cdot\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n & =fdB_{t}+\\left(B_{t}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}B_{t}\\right)dt+B_{t}\\frac{\\partial f}{\\partial x}dB_{t}\\\\\nB_{t}f & =\\int_{0}^{t}fdB_{s}+\\int_{0}^{t}\\left(B_{s}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}B_{s}\\right)ds+\\int_{0}^{t}B_{s}\\frac{\\partial f}{\\partial x}dB_{s}\\\\\n\\int_{0}^{t}fdB_{s} & =B_{t}f-\\int_{0}^{t}\\left(B_{s}\\frac{\\partial f}{\\partial t}+\\frac{\\partial f}{\\partial x}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}B_{s}\\right)ds-\\int_{0}^{t}B_{s}\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}$$\n\nApplying product rule to $tf(t,B_{t})$, we get:\n\n$$\\begin{aligned}\nd(tf) & =fdt+tdf+dt\\cdot df\\\\\n & =fdt+t\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n & +dt\\left(\\frac{\\partial f}{\\partial t}dt+\\frac{\\partial f}{\\partial x}dB_{t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}(dB_{t})^{2}\\right)\\\\\n & =fdt+t\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)dt+t\\frac{\\partial f}{\\partial x}dB_{t}\\\\\ntf & =\\int_{0}^{t}fds+\\int_{0}^{t}s\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)ds+\\int_{0}^{t}s\\frac{\\partial f}{\\partial x}dB_{s}\\\\\n\\int_{0}^{t}fds & =tf-\\int_{0}^{t}s\\left(\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\frac{\\partial^{2}f}{\\partial x^{2}}\\right)ds-\\int_{0}^{t}s\\frac{\\partial f}{\\partial x}dB_{s}\n\\end{aligned}$$\n\nThe following example will be important when we discuss the Girsanov theorem.\n\n::: {#thm-ito-formula-for-many-processes} \n\n### Ito's formula for many Ito processes\n\nLet $X_t = (X_t^{(j)},j\\leq d,j\\in\\mathbf{N})$ be Ito processes constructed on $(\\Omega,\\mathcal{F},\\mathbb{P})$ and $f \\in C^{1,2}([0,T]\\times \\mathbb{R}^d)$. Then for $t \\in [0,T]$, we have:\n\n$$\ndf(t,X_t) = \\partial_t f(t,X_t) dt + \\sum_{j=1}^{d} \\partial_{x_j} f(t,X_t) dX_t^{(j)} + \\frac{1}{2}\\sum_{j=1}^{d} \\sum_{k=1}^d \\partial_{x_j x_k}^2 f(t,X_t) dX_t^{(j)}\\cdot dX_t^{(k)}\n$$\n:::\n\n## Numerical Simulation of SDEs\n\nThe good news is that it is not too hard to implement iterative schemes to sample paths of a diffusion. Consider $(X_t,t\\leq T)$ a solution to the SDE:\n\n$$\ndX_t = \\sigma(X_t) dB_t + \\mu(X_t) dt\n$$\n\nTo keep the notation to a minimum, we consider a time-homogeonous diffusion. For a partition $(t_j,j\\leq n)$ of $[0,T]$ with $t_n = T$, consider the increment\n\n$$\nX_{t_{j+1}} - X_{t_j} = \\int_{t_j}^{t_{j+1}} \\sigma(X_s) dB(s) + \\int_{t_j}^{t_{j+1}} \\mu(X_s) ds\n$$ {#eq-increment-of-a-diffusion}\n\nNote that, if $\\sigma$ and $\\mu$ are smooth functions, we can apply Ito's formula to $\\sigma(X_s)$ and $\\mu(X_s)$ for $s\\in (t_j,t_{j+1}]$! We get:\n\n$$\n\\begin{align*}\n\\sigma(X_s) &= \\sigma(X_{t_j}) + \\int_{t_j}^{s}\\sigma'(X_u) dX_u + \\frac{1}{2}\\int_{t_j}^{s} \\sigma''(X_u)(dX_u)^2\\\\\n\\mu(X_s) &= \\mu(X_{t_j}) + \\int_{t_j}^{s}\\mu'(X_u) dX_u + \\frac{1}{2}\\int_{t_j}^{s} \\mu''(X_u)(dX_u)^2\n\\end{align*}\n$$ {#eq-ito-taylor-expansion-of-mu-and-sigma}\n\nNow, we can approximate the increment in @eq-increment-of-a-diffusion at different levels of precision by considering a different estimate for @eq-ito-taylor-expansion-of-mu-and-sigma. \n\n::: {#exm-euler-maruyama-scheme}\n\n(Euler-Maruyama Scheme). This scheme consists of taking $\\sigma(X_s) \\approx \\sigma(X_{t_j})$ and $\\mu(X_s) \\approx \\mu(X_{t_j})$ for $s \\in [t_j,t_{j+1})$ in @eq-ito-taylor-expansion-of-mu-and-sigma. Putting this back in @eq-increment-of-a-diffusion, we get:\n\n$$\nX_{t_{j+1}} - X_{t_j} \\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j)\n$$ {#eq-euler-maruyama}\n\nThe process $X_t$ can then be constructed recursively on the discrete set $(t_j,j \\leq n)$ as follows:\n\n$$\n\\begin{align*}\nX_0 &= x\\\\\nX_{t_1} &= (X_{t_1} - X_0) + X_0\\\\\nX_{t_2} &= (X_{t_2} - X_{t_1}) + (X_{t_1} - X_0) + X_0\\\\\n\\vdots\\\\\nX_{t_n} &= \\sum_{j=0}^{n-1}(X_{t_{j+1}} - X_{t_j}) + X_0\n\\end{align*}\n$$\n\n:::\n\n::: {#exm-milstein-scheme}\n\n(Milstein Scheme). In this scheme, we go an order further for the approximation of the volatility in @eq-ito-taylor-expansion-of-mu-and-sigma and consider also the integral in $dX_u$. We take $dX_u = \\sigma(X_{t_j})dB_u$. We then express $\\sigma(X_s)$ in @eq-ito-taylor-expansion-of-mu-and-sigma as:\n\n$$\n\\begin{align*}\n\\sigma(X_s) &\\approx \\sigma(X_{t_j}) + \\int_{t_j}^{s} \\sigma'(X_{t_j}) (\\sigma(X_{t_j})dB_u)\\\\\n&= \\sigma(X_{t_j}) + \\sigma'(X_{t_j}) \\sigma(X_{t_j}) \\int_{t_j}^{s}  dB_u\\\\\n&= \\sigma(X_{t_j}) + \\sigma'(X_{t_j}) \\sigma(X_{t_j}) (B_s - B_{t_j})\n\\end{align*}\n$$\n\nIf we put this back in @eq-increment-of-a-diffusion, we get:\n\n$$\n\\begin{align*}\nX_{t_{j+1}} - X_{t_j} &\\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\sigma'(X_{t_j}) \\sigma(X_{t_j}) \\int_{t_j}^{t_{j+1}} (B(s) - B(t_j))dB(s)\n\\end{align*}\n$$ {#eq-milstein-approx-step1}\n\nNow, consider the function $f(x)=x^2$. We have:\n\n$$\n\\begin{align*}\nf_x(x) &= 2x\\\\\nf_{xx}(x) &= 2\n\\end{align*}\n$$\n\nSo, we get:\n\n$$\nB^2(t_{j+1}) - B^2(t_j) = 2 \\int_{t_j}^{t_{j+1}} B(s) dB(s) + \\frac{1}{2} \\int_{t_j}^{t_{j+1}} (2) ds\n$$\n\nThus,\n\n$$\n\\int_{t_j}^{t_{j+1}} B(s) dB(s) = \\frac{1}{2}[(B_{t_{j+1}}^2 - B_{t_j}^2)-(t_{j+1}-t_j)]\n$$ {#eq-ito-integral-of-bm}\n\nSubstituting @eq-ito-integral-of-bm into @eq-milstein-approx-step1, we get the Milstein approximation:\n\n$$\n\\begin{align*}\nX_{t_{j+1}} - X_{t_j} &\\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+\\sigma'(X_{t_j}) \\sigma(X_{t_j})  \\left[\\frac{1}{2}((B_{t_{j+1}}^2 - B_{t_j}^2)-(t_{j+1}-t_j)) -  B_{t_j}(B_{t_{j+1}}-B_{t_j})\\right]\\\\\n&= \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\frac{\\sigma'(X_{t_j}) \\sigma(X_{t_j})}{2}  \\left[(B_{t_{j+1}}^2 - B_{t_j}^2)-(t_{j+1}-t_j) -  2B_{t_j}B_{t_{j+1}}+2B_{t_j}^2\\right]\\\\\n&= \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\frac{\\sigma'(X_{t_j}) \\sigma(X_{t_j})}{2}  \\left[(B_{t_{j+1}} - B_{t_j})^2-(t_{j+1}-t_j)\\right]\n\\end{align*}\n$$\n\nThus, under the Milstein scheme\n\n$$\n\\begin{align*}\nX_{t_{j+1}} - X_{t_j} &\\approx \\sigma(X_{t_j})(B_{t_{j+1}}-B_{t_j}) + \\mu(X_{t_j})(t_{j+1} - t_j) \\\\\n&+ \\frac{\\sigma'(X_{t_j}) \\sigma(X_{t_j})}{2}  \\left[(B_{t_{j+1}} - B_{t_j})^2-(t_{j+1}-t_j)\\right]\n\\end{align*}\n$$ {#eq-milstein}\n\nThe recursive nature of these two schemes makes them easy to implement numerically. The Milstein scheme is not much more costly to implement as it contains only one more term than the Euler scheme.\n:::\n\n### Python implementation\n\nLet's code an `SIVP` class and an abstract base class `Solver`.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom dataclasses import dataclass\nfrom abc import ABC, abstractmethod\nfrom typing import Callable, Optional\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\n\n# More descriptive type hints\nT = np.ndarray\nX = np.ndarray\n\n@dataclass\nclass SIVP:\n    \"\"\"\n    An abstraction for a stochastic initial value problem\n    \"\"\"\n    t_start : float\n    t_end : float\n    initial_condition: float\n\n    drift: Callable[[float, np.ndarray], np.ndarray]\n    vol: Callable[[float, np.ndarray], np.ndarray]\n    dvol_dx: Optional[Callable[[float, np.ndarray], np.ndarray]] = None\n\n\n\n@dataclass\nclass Solver(ABC):\n    \"\"\"\n    An abstract base class for all numerical schemes\n    \"\"\"\n\n    num_steps: int = 100\n    num_paths: int = 100\n\n    def __post_init__(self):\n        self.iter = 0\n\n        # x_values is a matrix of shape [num_paths,num_steps]\n        self.x_values = np.zeros((self.num_paths, self.num_steps + 1))\n        self.step_size = 1.0 / self.num_steps\n\n        # gaussian increments\n        self.brownian_increments = np.sqrt(self.step_size) * np.random.standard_normal(\n            size=(self.num_paths, self.num_steps)\n        )\n        self.brownian = np.cumsum(self.brownian_increments, axis=1)\n        self.brownian = np.concatenate(\n            [np.zeros(shape=(self.num_paths, 1)), self.brownian], axis=1\n        )\n\n    @abstractmethod\n    def iterate(self, sivp: SIVP) -> X:\n        \"\"\"\n        Compute the next iterate X(n+1)\n        \"\"\"\n\n    def solve(self, sivp: SIVP) -> (T, X):\n        \"\"\"\n        Solve the SIVP\n        \"\"\"\n        self.x_values[:, 0] = np.full(\n            shape=(self.num_paths,), fill_value=sivp.initial_condition\n        )\n        while self.iter < self.num_steps:\n            self.x_values[:, self.iter + 1] = self.iterate(sivp)\n            self.iter += 1\n\n        times = np.linspace(sivp.t_start, sivp.t_end, self.num_steps + 1)\n        return times, self.x_values\n\n    def reset(self):\n        self.__post_init__()\n```\n:::\n\n\nThe `EulerMaruyama` and `Milstein` methods will derive from the abstract base class `Solver`.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n@dataclass\nclass EulerMaruyama(Solver):\n    \"\"\"\n    Numerical solver for a stochastic differential equation(SDE) using\n    the Euler-Maruyama method.\n\n    Consider an SDE of the form :\n\n    dX_t = mu(t,X_t) dt + sigma(t,X_t) dB_t\n\n    with initial condition X_0 = x_0\n\n    The solution to the SDE can be computed using the increments\n\n    X_{n+1} - X_n = mu(n,X_n)(t_{n+1}-t_n) + sigma(n,X_n)(B(n+1)-B(n))\n\n    \"\"\"\n\n    def iterate(self, sivp: SIVP) -> X:\n        \"\"\"\n        Generate the next iterate X(n+1)\n        \"\"\"\n        current_time = self.iter * self.step_size\n        mu_n = sivp.drift(current_time, self.x_values[:, self.iter])\n        sigma_n = sivp.vol(current_time, self.x_values[:, self.iter])\n        delta_x = (\n            mu_n * self.step_size + sigma_n * self.brownian_increments[:, self.iter]\n        )\n        return self.x_values[:, self.iter] + delta_x\n```\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n@dataclass\nclass Milstein(Solver):\n    \"\"\"\n    Numerical solver for a stochastic differential equation(SDE) using\n    the Euler-Maruyama method.\n\n    Consider an SDE of the form :\n\n    dX_t = mu(t,X_t) dt + sigma(t,X_t) dB_t\n\n    with initial condition X_0 = x_0\n\n    The solution to the SDE can be computed using the increments\n\n    X_{n+1} - X_n = mu(n,X_n)(t_{n+1}-t_n) + sigma(n,X_n)(B(n+1)-B(n))\n    + 0.5 * sigma(n,X_n) * sigma'(n,X_n) * ((B(n+1) - B(n))**2 - (t_{n+1} - t_n))\n\n    \"\"\"\n\n    def iterate(self, sivp: SIVP):\n        \"\"\"\n        Generate the next iterate X(n+1)\n        \"\"\"\n        current_time = self.iter * self.step_size\n        mu_n = sivp.drift(current_time, self.x_values[:, self.iter])\n        sigma_n = sivp.vol(current_time, self.x_values[:, self.iter])\n        dvol_dx_n = sivp.dvol_dx(current_time, self.x_values[:, self.iter])\n\n        delta_x = (\n            mu_n * self.step_size\n            + sigma_n * self.brownian_increments[:, self.iter]\n            + 0.5\n            * sigma_n\n            * dvol_dx_n\n            * (self.brownian_increments[:, self.iter] ** 2 - self.step_size)\n        )\n\n        return self.x_values[:, self.iter] + delta_x\n```\n:::\n\n\n::: {#exr-simulating-sdes}\n\n(Simulating SDEs) Simulate 100 paths for the following diffusions given by their SDEs on $[0,1]$ using the Euler-Maruyama scheme and the Milstein scheme for a discretization of $0.01$.\n\n(a) Geometric Brownian Motion: \n\n$$\ndS_t = S_t dB_t + \\left(\\mu + \\frac{\\sigma^2}{2}\\right)S_t dt, \\quad S_0 = 1\n$$\n\nfor $\\mu=-1/2$, $\\mu=-2$, and $\\mu=0$\n\n(b) Ornstein-Uhlenbeck process:\n\n$$\ndX_t = -X_t dt + dB_t, \\quad X_0 = 1\n$$\n\n(c) The diffusion:\n\n$$\ndX_t = \\sqrt{1+X_t^2}dB_t + \\sin X_t dt, \\quad X_0 = 0\n$$\n:::\n\n*Solution.*\n\nWe can now use `EulerMaruyama` and `Milstein` solvers and generate some sample paths. \n\n::: {.cell execution_count=4}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\ndef plot_trajectories(ts, xs, title):\n    plt.xlabel(r'Time $t$')\n    plt.ylabel(r'$X(t)$')\n    plt.title(title)\n    plt.grid(True)\n    plt.plot(ts, xs.transpose())\n    plt.show()\n\n# mu = -0.5 case\neuler = EulerMaruyama(num_paths=10, num_steps=100)\n\ngbm_sde = SIVP(\n    t_start=0.0,\n    t_end=1.0,\n    initial_condition=1.0,\n    drift=lambda t, s_t: np.zeros(10),\n    vol=lambda t, s_t: s_t,\n    dvol_dx=lambda t, s_t: np.ones(10),\n)\n\n\nts, xs = euler.solve(gbm_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Geometric Brownian Motion, $\\mu=-0.5$')\n\n# mu = -2 case\ngbm_sde.drift = lambda t, s_t : -1.5 * s_t\nts, xs = euler.solve(gbm_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Geometric Brownian Motion, $\\mu=-2.0$')\n\n# mu = 0 case\ngbm_sde.drift = lambda t, s_t : 0.5 * s_t\nts, xs = euler.solve(gbm_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Geometric Brownian Motion, $\\mu=0.0$')\n\n# ornstein-uhlenbeck\nornstein_uhlenbeck_sde = SIVP(\n    t_start=0.0,\n    t_end=1.0,\n    initial_condition=1.0,\n    drift = lambda t, s_t : -s_t,\n    vol = lambda t, s_t : np.ones(10),\n    dvol_dx = lambda t, s_t : np.zeros(10)\n)\n\nts, xs = euler.solve(ornstein_uhlenbeck_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of Ornstein-Uhlenbeck')\n\n# diffusion\ndiffusion_sde = SIVP(\n    t_start=0.0,\n    t_end=1.0,\n    initial_condition=0.0,\n    drift = lambda t, s_t : np.sin(s_t),\n    vol = lambda t, s_t : np.sqrt(1+s_t**2),\n    dvol_dx = lambda t, s_t : s_t / np.sqrt(1 + s_t**2) \n)\n\nts,xs = euler.solve(diffusion_sde)\neuler.reset()\n\nplot_trajectories(ts, xs, r'10 sample paths of the diffusion')\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-1.png){width=576 height=448}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-2.png){width=595 height=448}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-3.png){width=576 height=448}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-4.png){width=595 height=447}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-5.png){width=591 height=447}\n:::\n:::\n\n\n### Convergence\n\nIt is of course possible go beyond the Milstein scheme to improve the approximation. However, it turns out that the above schemes already converge quite rapidly to the process itself. To see this, consider the mean absolute error between the approximation $X_T^{(n)}$ at time $T$ and $X_T$. Suppose that the approximation $X^{(n)}$ is obtained for a partition with discretization $t_{j+1}-t_j = 1/n$. It is possible to show that for the Euler scheme, we have:\n\n$$\n\\begin{align*}\n\\mathbb{E}[|X_T^{(n)} - X_T|] \\leq \\frac{C}{\\sqrt{n}}\n\\end{align*}\n$$\n\nwhereas for the Milstein scheme\n\n$$\n\\begin{align*}\n\\mathbb{E}[|X_T^{(n)} - X_T|] \\leq \\frac{C'}{n}\n\\end{align*}\n$$\n\nfor some constants $C,C'>0$. Note that the mean error between the two process must be the worst at the last point, since the errors add up. \n\n## Existence and Uniqueness of SDEs\n\nAs for the differential equations in standard calculus, SDEs play an important role in modelling stochastic phenomena. To model a trajectory $X_t, t\\leq T$, it suffices to write down the variation due to the deterministic change $\\mu(X_t)dt$ for some function $\\mu(X_t)$ and the variation due to local fluctuations $\\sigma(X_t)dB_t$ for some function $\\sigma(X_t)$. Here, we assume that the local drift and volatility are time-homogenous for simplicity. This gives the SDE:\n\n$$\ndX_t = \\mu(X_t) dt + \\sigma(X_t) dB_t\n$$ \n\nDo we get one nice Ito process for any choice of functions $\\sigma$ and $\\mu$? The short answer is no. Here are sufficient conditions for the existence of a unique process. \n\n::: {#thm-existence-and-uniqueness-of-solutions-to-sde}\n### Existence and Uniqueness of solutions to SDE\n\nConsider the SDE\n\n$$\ndX_t = \\mu(X_t) dt  + \\sigma(X_t)dB_t, \\quad X_0 = x, \\quad t\\in [0,T]\n$$\n\nIf the functions $\\sigma$ and $\\mu$ grow not faster than $Kx^2$ for some $K>0$ and are differentiable with bounded derivatives on $\\mathbb{R}^1$, then there exists a unique solution $(X_t,t\\in[0,T])$ to the SDE. In other words, there exists a continuous process $(X_t, t \\leq T)$ adapted to the filtration of the Brownian motion given by:\n\n$$\nX_t = x + \\int_0^t \\mu(X_s) ds + \\int_0^t \\sigma(X_s) dB_s, \\quad t\\leq T\n$$\n\n:::\n\n::: {#exm-diffusion}\n\nConsider the SDE :\n\n$$\ndX_t = \\sqrt{1 + X_t^2}dB_t + \\sin X_t dt\n$$ {#eq-a-diffusion}\n\nThere exists a unique diffusion process $(X_t,t\\geq 0)$ that is a solution of this SDE. To see this, we verify the conditions of the  @thm-existence-and-uniqueness-of-solutions-to-sde. We have:\n\n$$\n\\sigma(x) = \\sqrt{1 + x^2}, \\quad \\mu(x) = \\sin x\n$$\n\nClearly, these functions satisfy the growth condition since $\\mu$ is bounded and $\\sigma$ grows like $|x|$ for large $x$. As for the derivatives, we have $\\sigma'(x)=\\frac{x}{\\sqrt{1+x^2}}$ and $\\mu'(x)=\\cos x$. The two derivatives are bounded. \n:::\n\nThe assumptions of @thm-existence-and-uniqueness-of-solutions-to-sde are not too surprising, since similar ones are found in the classical case of ODE. For example, if we have the ODE\n\n$$\n\\frac{dX_t}{dt} = X_t^{1/2}, \\quad X_0 = 0\n$$\n\nthen clearly $X_t = 0$ for all $t$ is a solution. But, we also have by integrating that:\n\n$$\nX_t = \\frac{t^2}{4}, t \\geq 0\n$$\n\nTherefore, the uniqueness breaks down. Note, that the function $\\mu(x)=\\sqrt{x}$ does not have bounded derivatives at $0$. Similarly, consider the ODE:\n\n$$\n\\frac{dX_t}{dt} = e^{X_t}, X_0 = 0\n$$\n\nHere, the function $\\mu(x)$ grows much faster than $x^2$. The solution of the ODE is by integrating \n\n$$\n\\begin{align*}\n-(e^{-X_t} - 1) &= t\\\\\ne^{-X_t} &= (1 - t)\\\\\n-X_t &= \\log(1 - t)\\\\\nX_t &= \\log \\left(\\frac{1}{1-t}\\right)\n\\end{align*}\n$$\n\nThe solution explodes at $t=1$. The same phenomenon may occur for SDE; that is the process will almost surely go $\\infty$ in finite time. These times are called *explosion times*. Note that it is possible to consider the paths of the diffusion upto these explosion times. It is important to keep in mind that the conditions of  @thm-existence-and-uniqueness-of-solutions-to-sde are sufficient, but not necessary. In particular, it is sometimes possible to explicitly construct a diffusion whose local volatility and drift do not satisfy the conditions. Let's look at two important instances of such diffusions.\n\n::: {exm-bessel-process}\nLet $B_t$ be a brownian motion in $\\mathbb{R}^d$ for $d>1$. Consider the process giving the distance at time $t$ of $B_t$ to the origin; that is:\n\n$$\nR_t = ||B_t|| = \\left(\\sum_{j=1}^d B_t^{(j)}\\right)^2\n$$\n\n(For $d=1$, this is simply $|B_t|$. Ito's formula cannot be applied in this case, since the absolute value is not differentiable at the origin.) In higher dimensions, the function is smooth enough as long as we stay away from the origin. This is not a problem as long as $R_0 > 0$. \n:::\n\nLet's find out the SDE that this process satisfies. \n\nLet $r=f(x_1,x_2,\\ldots,x_d)=\\sqrt{\\sum_{j=1}^d x_j^2}$. We have:\n\n\\begin{align*}\n\\frac{\\partial r}{\\partial x_j} &= \\frac{x_j}{\\sqrt{\\sum_{j=1}^d x_j^2}}\\\\\n\\frac{\\partial^2 r}{\\partial x_j^2} &= \\frac{||x|| - x_j \\cdot \\frac{x_j}{||x||}}{||x||^2}\\\\\n&= \\frac{||x||^2 - x_j^2}{||x||^3}\n\\end{align*}\n\nBy Ito's formula,\n\n\\begin{align*}\ndR_t &= \\sum_{j=1}^{d} \\frac{B_t^{j}}{R_t} dB_t^{(j)} + \\frac{1}{2} \\sum_{j=1}^{d} \\frac{R_t^2 - (B_t^{(j)})^2}{R_t^3}\\\\\n&= \\sum_{j=1}^{d} \\frac{B_t^{j}}{R_t} dB_t^{(j)} + \\frac{1}{2} \\frac{d R_t^2 - R_t^2}{R_t^3}\\\\\n&= \\sum_{j=1}^{d} \\frac{B_t^{j}}{R_t} dB_t^{(j)} + \\frac{1}{2} \\frac{(d-1)}{R_t}\n\\end{align*}\n\nWe can define $dW_t = \\sum_{j=1}^{d} \\frac{B_t^{(j)}}{R_t} dB_t^{(j)}$. Then, $dR_t = dW_t + \\frac{d-1}{2R_t}dt$\n\nIt turns out that $(W_t,t \\geq 0)$ is a standard Brownian motion by Levy's characterization theorem. This is the subject of the next section. The SDE shows that $dR_t$ is a diffusion. The SDE makes sense for any real number $d > 1$, not only integers. Moreover, the SDE is well-defined since $R_t$ is never equal to $0$. However, the SDE does not satisfy the assumption of the existence and uniqueness of the solution of SDEs since $1/x$ diverges at $0$. The solution to the SDE still exists since we constructed it! We sample paths of this process in numerical project.\n\n::: {#exm-cox-ingersoll-ross-process}\n\n### The Cox-Ingersoll-Ross (CIR) model.\n\nConsider the SDE:\n\n$$\ndS_t = \\sigma \\sqrt{S_t} dW_t + (a - bS_t)dt, \\quad S_0 > 0\n$$ {#eq-cir-process}\n\nfor some parameters $a,b > 0$ where $(W_t,t \\geq 0)$ is a standard Brownian motion. The local volatility $\\sigma(x)=\\sigma \\sqrt{x}$ does not have a bounded derivative close to $0$, since $\\sigma'(x)=\\frac{\\sigma}{2\\sqrt{x}}$. We will nevertheless construct a diffusion that is a solution to the SDE. Consider independent Ornstein-Uhlenbeck processes $X_t^{(j)}, j \\leq d$, with SDE:\n\n$$\ndX_t^{(j)} = \\frac{-b}{2}X_t^{(j)}dt + \\frac{\\sigma}{2}dB_t^{(j)}, \\quad X_0^{(j)} > 0\n$$\n\nwhere $B_t = (B_t^{(j)},j\\leq d)$ is a Brownian motion in $\\mathbb{R}^d$. We consider the process \n\n$$\nS_t = \\sum_{j \\leq d} (X_t^{(j)})^2\n$$\n\nClearly, $S_t$ is nongegative for all $t \\geq 0$ by design, so $\\sqrt{S_t}$ is well-defined. Let's compute the SDE of the process. By Ito's formula, we have:\n\n$$\n\\begin{align*}\ndS_t &= 2\\sum_{j=1}^{d}X_t^{(j)} dX_t^{(j)} + \\frac{1}{2}\\sum_{j=1}^{d} 2 (dX_t^{(j)})^2\\\\\n&=2\\sum_{j=1}^{d}X_t^{(j)} dX_t^{(j)} + \\frac{\\sigma^2}{4}\\sum_{j=1}^{d} dt \\\\\n&=2\\sum_{j=1}^{d}X_t^{(j)} \\left(\\frac{-b}{2}X_t^{(j)}dt + \\frac{\\sigma}{2}dB_t^{(j)}\\right) + \\frac{d\\sigma^2}{4} dt\\\\\n&=\\left[\\left(\\sum_{j=1}^d (-b)(X_t^{(j)})^2\\right) + \\frac{d\\sigma^2}{4}\\right] dt + \\sigma \\sum_{j=1}^{d} X_t^{(j)} dB_t^{(j)}\\\\\n&=\\sigma \\sum_{j=1}^{d} X_t^{(j)} dB_t^{(j)} + \\left[\\frac{d\\sigma^2}{4} - b S_t\\right] dt \\\\\n&= \\sigma \\sqrt{S_t} \\sum_{j=1}^{d} \\frac{X_t^{(j)}}{\\sqrt{S_t}} dB_t^{(j)}  + \\left[\\frac{d\\sigma^2}{4} - b S_t\\right] dt \\\\\n&= \\sigma \\sqrt{S_t} dW_t  + \\left[\\frac{d\\sigma^2}{4} - b S_t\\right] dt \\\\\n\\end{align*}\n$$\n\nwhere we have defined $dW_t = \\sum_{j=1}^d \\frac{X_t^{(j)}}{\\sqrt{S_t}} dB_t^{(j)}$. It turns out that the process $(W_t,t\\geq 0)$ is a standard brownian motion by Levy's characterization theorem. If we accept this for a moment, we have the SDE:\n\n$$\ndS_t = \\sigma \\sqrt{S_t} dW_t + \\left(\\frac{d \\sigma^2}{4} - bS_t\\right) dt, \\quad S_0 > 0\n$$ {#eq-cir-process-2}\n\nThis is a time-homogenous diffusion called the Cox-Ingersoll-Ross (CIR) process. Again, notice that there are no issues with square root, since $S_t$ is positive by construction! The SDE also makes sense if replace $d\\sigma^2/4$ by a parameter $a$ in @eq-cir-process  as long as $a \\geq \\frac{d\\sigma^2}{4}$. This process is important for interest rates and stochastic volatility models.\n\nNote that the local drift is $a - bS_t, a\\ge \\frac{d\\sigma^2}{4}$. This can be written as:\n\n\\begin{align*}\na - bS_t = b\\left(\\frac{b}{a} - S_t \\right)\n\\end{align*}\n\nThis means that the local drift is negative if $S_t > \\frac{a}{b}$ and it is positive if $S_t < \\frac{a}{b}$. So, the SDE exhibits the same phenomenon as for the SDE of the Ornstein-Uhlenbeck process in @exm-ornstein-uhlenbeck-process. In particular we should expect that for $t$ large, the process should fluctuate around the mean value $\\frac{a}{b}$. The CIR model is therefore an example of a mean-reverting process. More generally, this hints to the fact, that the process is stationary in the long run. \n:::\n\n## Martingale Representation and Levy's Characterization\n\nWe know very well by now, that an Ito integral is continuous martingale with respect to the Brownian filtration, whenever the integrand is in $\\mathcal{L}_c^2(T)$. What can we say about the converse? In other words, if we have a martingale with respect to the Brownian filtration, can it be expressed as an Ito integral for some integrand $(V_t,t\\leq T)$? Amazingly, the answer to this question is yes!\n\n::: {#thm-martingale-representation-theorem}\n\n### Martingale Representation Theorem.\n\nLet $(B_t,t \\geq 0)$ be a Brownian motion with filtration $(\\mathcal{F}_t,t\\geq 0)$ on $(\\Omega,\\mathcal{F},\\mathbb{P})$. Consider a martingale $(M_t,t\\leq T)$ with respect to this filtration. Then, there exists an adapted process $(V_t,t \\leq T)$ such that:\n\n$$\nM_t = M_0 + \\int_0^t V_s dB_s, \\quad t \\leq T\n$$ {#eq-martingale-representation-theorem}\n\nOne striking fact of the result is that $(M_t,t\\leq T)$ ought to be continuous. In other words, we cannot construct a process with a jump that is a martingale adapted to Brownian motion!\n\nInstead of the proving the theorem, we will see how the result is not too surprising with stronger assumptions. Instead of supposing that $M_t$ is $\\mathcal{F}_t$ measurable, take that $M_t$ is $\\sigma(B_t)$-measurable. In other words, $M_t=h(B_t)$ for some function $h$. In the case where $h$ is smooth, then it is clear by Ito's formula that the representation @eq-martingale-representation-theorem holds with $V_s = h'(B_s)$. \n:::\n\nAn important consequence of @thm-martingale-representation-theorem is a third definition of Brownian motion.\n\n::: {#thm-levy-characterization-theorem}\n\n### One-dimensional Levy's Characterization theorem\n\nLet $(M_t,t\\in [0,T])$ be a continuous martingale with respect to the filtration $(\\mathcal{F}_t,t \\leq T)$ with $M_0 = 0$ and with quadratic variation $<M>_t = t$. Then, $(M_t,t\\leq T)$ is a standard brownian motion. \n:::\n\n*Proof.*\n\nWe first need to show that $M_t - M_s \\sim \\mathcal{N}(0,t - s)$ or using the characteristic function approach, we need to show that $f_{(M_t - M_s)}(\\theta)=\\mathbb{E}[e^{\\theta (M_t - M_s)}] = e^{\\frac{1}{2}\\theta^2 (t-s)}$ for constant $\\theta$.\n\nLet $f(t,x) = e^{\\theta x - \\frac{1}{2}\\theta^2 t}$.\n\nBy Ito's formula, we have:\n\n\\begin{align*}\ndf(t,M_t) &= \\theta e^{\\theta M_t - \\frac{1}{2}\\theta^2 t} dM_t + \\left(-\\frac{1}{2}\\theta^2 + \\frac{1}{2} \\theta^2 \\right)e^{\\theta M_t - \\frac{1}{2}\\theta^2 t}dt\\\\\n&= \\theta f(t,M_t) dM_t\n\\end{align*}\n\nIntegrating on both sides, we get:\n\n\\begin{align*}\nf(t,M_t) - f(s,M_s) &= \\theta \\int_0^t f(u,M_u) dM_u\n\\end{align*}\n\nThe ito integral $\\int_0^t f(s,M_s) dM_s$ is well-defined and its expectation is $0$. Hence, applying expectation operator on both sides, we get:\n\n\\begin{align*}\n\\mathbb{E}[f(t,M_t) - f(s,M_s)] &= \\theta \\mathbb{E} \\left[ \\int_0^t f(s,M_s) dM_s\\right]\\\\\n&= 0 \n\\end{align*}\n\nSince $e^{x} \\neq 0$ for all $x$, dividing by $f(s,M_s)$, we get:\n\n\\begin{align*}\n\\mathbb{E}\\left[\\frac{f(t,M_t)}{f(s,M_s)}\\right] &= 1\\\\\n\\mathbb{E}\\left[\\frac{e^{\\theta M_t - \\frac{1}{2}\\theta^2 t}}{e^{\\theta M_s - \\frac{1}{2}\\theta^2 s}}\\right] &= 1\\\\\n\\mathbb{E}\\left[e^{\\theta(M_t - M_s)}\\right] &= e^{\\frac{1}{2}\\theta^2(t-s)}\n\\end{align*}\n\nwhich is the moment generating function for the normal distribution with mean zero and variance $t-s$. So, $M_t - M_s \\sim \\mathcal{N}(0, t - s)$. \n\nFurther, consider $t_1 \\leq t_2 \\leq t_3$. We have:\n\n\\begin{align*}\n\\mathbb{E}[(M_{t_3} - M_{t_2})(M_{t_2} - M_{t_1})] &= \\mathbb{E}[\\mathbb{E}[(M_{t_3} - M_{t_2})(M_{t_2} - M_{t_1})|\\mathcal{F}_{t_2}]] \\\\\n&= \\mathbb{E}[(M_{t_2} - M_{t_1})\\mathbb{E}[(M_{t_3} - M_{t_2})|\\mathcal{F}_{t_2}]] \\\\\n&= \\mathbb{E}[(M_{t_2} - M_{t_1})(M_{t_2} - M_{t_2})] \\\\\n&= 0\n\\end{align*}\n\nwhere $\\mathbb{E}[M_{t_3} - M_{t_2}|\\mathcal{F}_{t_2}] = 0$ follows from the fact that $(M_t,t\\geq 0)$ is a martingale. Consequently, $M_{t_3} - M_{t_2} \\perp M_{t_2} - M_{t_1}$ and non-overlapping increments are independent.\n\nMoreover, $M(0) = 0$. So, $(M_t,t\\geq 0)$ is a standard brownian motion. This closes the proof. $\\blacksquare$\n\n\n## Exercise Problems\n\n::: {#exr-power-of-bm}\n\nLet $(\\Omega,\\mathcal{F},\\mathbb{P})$ be a probability space and $(W_t,t\\geq 0)$ be a standard Wiener process. Find the SDE for the random process $X_t = W_t^n, n \\in \\mathbb{Z}^{+}$.\n\nShow that\n\n$$\n\\mathbb{E}[W_t^n] = \\frac{1}{2}n(n-1) \\int_0^t \\mathbb{E}\\left[W_s^{(n-2)}\\right] ds\n$$\n\nand using mathematical induction prove that:\n\n$$\n\\mathbb{E}[W_t^n] = \\begin{cases}\n\\frac{n! t^{n/2}}{2^{n/2} \\left(\\frac{n}{2}\\right)!}, & n=2,4,6,\\ldots\\\\\n0, & n=1,3,5,\\ldots\n\\end{cases}\n$$\n:::\n\n*Solution.*\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}