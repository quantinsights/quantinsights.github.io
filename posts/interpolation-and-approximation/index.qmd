---
title: "Interpolation and Approximation"
author: "Quasar"
date: "2024-11-13"
categories: [Numerical Methods]      
image: "image.jpg"
toc: true
toc-depth: 3
---

## Introduction

In this blog post, I would like to implement some interpolation algorithms using modern C++. It's important we understand *how* and *why* these algorithms work. Because there are nuances, exceptions and corner-cases, we need to understand. It's a great learning experience! You never fully understand something like the $QR$-algorithm (which is actually incredibly complicated to get the details right), unless you spend some time implementing it. A lot of the skills you pick up will translate when you write numerical codes.

Even if you have excellent implementations of any algorithm, you still need to understand some of the internals in order to make good use of your library. For example, any linear algebra library can compute an inverse matrix really fast and as accurately as mathematics allows. But, you have to know a little theory in order to know that you should still avoid using that if at all possible. (Matrix decomposition and solving without explicitly computing the inverse is better, generally speaking). 

## The Interpolation Problem

Polynomials are used as the basic means of approximation and are ubiquitous in nearly all areas of computational science. 

Let $a=x_1 < x_2 < \ldots < x_n = b$ be a grid of distinct points. Let $\mathcal{P}_n$ be the vector space of of polynomials in one variable with degree $\leq n - 1$. We are interested to find a polynomial $p \in \mathcal{P}_n$ such that:

$$
\begin{align*}
p(x_i) = f(x_i), \quad i = 1 : n
\end{align*}
$$ {#eq-interpolation-problem}

::: {#thm-uniqueness-of-the-interpolating-polynomial}

### Uniqueness of the interpolating polynomial

If $x_1,\ldots,x_n$ are distinct real numbers, then for arbitrary values $y_1,\ldots,y_n$, there is a unique polynomial $p\in \mathcal{P}_{n}$ of degree at most $n-1$ such that:

$$p(x_i) = y_i,  \quad i = 1 : n$$
:::

*Proof.*

Suppose that there were two such polynomials $p$ and $q$. Then, the polynomial $p-q$ would have the property $(p-q)(x_i)=0$ for $1 \leq i \leq n$. Since, the degree of $(p-q)$ can be at most $n-1$, this polynomial can have atmost $(n-1)$ zeroes, if is not the $0$ polynomial. Since the $x_i$'s are distinct, it follows that:

$$
(p-q)(x) = (x - x_1)(x - x_2)\ldots(x-x_n) = \prod_{i=1}^n (x-x_i)
$$

and it has atleast $n$ zeroes. Hence, $(p-q)(x)\equiv 0$ - it must be identically equal to zero. So, $p(x) = q(x)$ for all $x$. This closes the proof. $\blacksquare$

### Bases for polynomial interpolation

A set of polynomials $\{p_1(x), p_2(x), \ldots, p_n(x)\}$ such that the polynomial $p \in \mathcal{P}_n$ can be expressed as a linear combination :

$$
p(x) = \sum_{j=1} c_j p_j(x)
$$

is called a basis for $\mathcal{P}_n$. The column vector $c=(c_1,c_2,\ldots,c_n)^T$ can be viewed as the coordinate vector of $p$ in the polynomial space $\mathcal{P}_n$. The inerpolation problem leads to a system of equations:

$$
\begin{align*}
c_1 p_1(x_i) + c_2 p_2(x_i) + \ldots + c_n p_n(x_i) = f(x_i), \quad i=1:n
\end{align*}
$$ {#eq-system-of-equations}

If we introduce the matrix :

$$
\begin{align*}
P_n = [p_j(x_i)]_{i,j=1}^n
\end{align*}
$$ {#eq-matrix}

and the column vector $f=(f(x_1),\ldots,f(x_n))^T$, then the linear system becomes:

$$
\begin{align*}
P_n c = f
\end{align*}
$$ {#eq-matrix-form-of-eq}

Mathematically, the choice of a basis (for a finite-dimensional space) makes no difference. Computationally, when working with *rounded values of coefficients*, the choice of basis can make a great difference. If the purpose is to compute derivatives or integrals of the interpolation polynomial, the power basis or the **shifted power basis**, where $p_j(x) = (x - c)^{j-1}$ that is:

$$
p(x)= \sum_{j=1}^n c_j(x)(x - c)^{j-1}
$$

is convenient although not always the best. If a shifted power basis is to be used for polynomial approximation on an interval $[a,b]$, it is often the best to choose $c = (a + b)/2$, equal to the midpoint of the interval. 

For the **power basis** $p_j(x) = x^{j-1}$, the coefficients of the interpolation polynomial are given by the solution of the linear system $V_n^T c = f$, where $V_n$ is the Vandermonde matrix

$$
V_n = [x_j^{i-1}]_{i,j=1}^n = 
\begin{bmatrix}
1 & 1 & \ldots & 1\\
x_1 & x_2 & \ldots & x_n \\
\vdots & \vdots & \ldots & \vdots\\
x_1^{n-1} & x_2^{n-1} & \ldots & x_n^{n-1}
\end{bmatrix}
$$ {#eq-vandermonde-matrix}

## Piecewise Polynomial Interpolation

Interpolating a given function by a single polynomial over its entire range can be an ill-conditioned problem, as illustrated by *Runge's phenomenon*. On the other hand, polynomials of low degree can give good approximations *locally* in a small interval. I would like to discuss approximation schemes for **piecewise polynomial interpolation** with different degrees of global continuity.

With the use of piecewise polynomials, there is no reason to fear equidistant data, as opposed to the situation with higher-degree polynomials. In computer graphics and computer-aided design(CAD), curves and surfaces have to be represented mathematically, so that they can be manipulated and visualized easily. In 1962, [Bezier](https://en.wikipedia.org/wiki/Pierre_B%C3%A9zier) and [de Casteljau](https://en.wikipedia.org/wiki/Paul_de_Casteljau), working for French car companies Renault and Citroen, independently developed Bezier curves for fitting curves and surfaces. Similar work, using bicubic splines, was done in USA at general motors by Garret Birkhoff and Henry Garabedian. 

Today, Bezier curves and spline functions are used extensively in all aircraft and automotive industries. Spline functions can also be used in the numerical treatment of boundary value problems for differential equations. Bezier curves have found use in computer graphics and typography. Trutype font glyphs are made of quadratic bezier curves. 



