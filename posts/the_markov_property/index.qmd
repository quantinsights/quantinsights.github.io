---
title: "The Markov Property"
author: "Quasar"
date: "2024-07-12"
categories: [Stochastic Calculus]      
image: "image.jpg"
toc: true
toc-depth: 3
---

## The Markov Property for Diffusions

Let's start by exhibiting the Markov property of Brownian motion. To see this, consider $(\mathcal{F}_t,t\geq 0)$, the natural filtration of the Brownian motion $(B_t,t\geq 0)$. Consider $g(B_t)$ for some time $t$ and bounded function $g$. (For example, $g$ could be an indicator function.) Consider also a random variable $W$ that is $\mathcal{F}_s$ measurable for $s < t$. (For example, $W$ could be $B_s$ or $1_{B_s > 0}$.) Let's compute $\mathbb{E}[g(B_t)W]$.

\begin{align*}
\mathbb{E}[g(B_t)W] &= \mathbb{E}[\mathbb{E}[Wg(B_t - B_s + B_s)|\mathcal{F}_s]]
\end{align*}

The random variable $(B_t - B_s)$ follows a $\mathcal{N}(0,t-s)$ distribution. By LOTUS,

\begin{align*}
\mathbb{E}[g(B_t)W] 
&= \int_{\mathbb{R}} \mathbb{E}[W g(y + B_s)|\mathcal{F_s}]f_{(B_t - B_s)|B_s}(y) dy\\
&= \{\text{ Using the fact that }B_t - B_s \perp B_s\}\\
&= \int_{\mathbb{R}} \mathbb{E}[W g(y + B_s)]f_{(B_t - B_s)}(y)dy\\
&= \int_{\mathbb{R}} \mathbb{E}[W g(y + B_s)]\frac{e^{-\frac{y^2}{2(t-s)}}}{\sqrt{2\pi(t-s)}}dy
\end{align*}

By Fubini's theorem, the integral and the expectation operator can be interchanged, and since $W$ is $\mathcal{F}_s$ measurable, it follows from the definition of conditional expectations that:

$$
\begin{align*}
\mathbb{E}[g(B_t)|\mathcal{F}_s] &= \int_{\mathbb{R}} g(y + B_s) \frac{e^{-\frac{y^2}{2(t-s)}}}{\sqrt{2\pi(t-s)}}dy
\end{align*}
$$ {#eq-conditional-expectation-of-function-brownian-motion}

We make two important observations. First, the right hand side is a function of $s,t$ and $B_s$ only (and not of the Brownian motion before time s). In particular, we have:

$$
\mathbb{E}[g(B_t)|\mathcal{F}_s] = \mathbb{E}[g(B_t)|B_s]
$$

This holds for any bounded function $g$. In particular, it holds for all indicator functions. This implies that the conditional distribution of $B_t$ given $\mathcal{F}_s$ depends solely on $B_s$, and not on other values before time $s$. Second, the right-hand side is *time-homogenous* in the sense that it depends on the time difference $t-s$. 

We have just shown that Brownian motion is a *time-homogenous Markov process*. 

::: {#def-markov-process}

### Markov process.

Consider a stochastic process $(X_t,t\geq 0)$ and its natural filtration $(\mathcal{F}_t,t\geq 0)$. It is said to be a *Markov process* if and only if for any (bounded) function $g: \mathbb{R} \to \mathbb{R}$, we have:

$$
\mathbb{E}[g(X_t) | \mathcal{F}_s] = \mathbb{E}[g(X_t) | X_s], \quad \forall t \geq 0, \forall s \leq t
$$ {#eq-markov-process}

:::

This implies that $\mathbb{E}[g(X_t)|\mathcal{F}_s]$ is an explicit function of $s$, $t$ and $X_s$. It is said to be *time-homogenous*, if it is a function of $t-s$ and $X_s$. Since the above holds for all bounded $g$, the conditional distribution of $X_t$ given $\mathcal{F}_s$ is the same as the conditional distribution of $X_t$ given $X_s$. 

One way to compute the conditional distribution of $X_t$ given $\mathcal{F}_s$ is to compute the conditional MGF given $\mathcal{F}_s$, that is:

$$
\mathbb{E}[e^{a X_t}|\mathcal{F}_s], \quad a \geq 0
$$ {#eq-conditional-mgf-of-xt}

The process would be Markov, if the conditional MGF is an explicit function of $s$, $t$ and $X_s$. 

::: {#exm-brownian-motion-is-markov}

(Brownian Motion is Markov) Let $(B_t,t\geq 0)$ be a standard brownian motion. Our claim is that the brownian motion is a markov process.
:::

*Proof.*

We have:

\begin{align*}
\mathbb{E}[e^{a B_t}|\mathcal{F}_s] &= \mathbb{E}[e^{a (B_t - B_s + B_s)}|\mathcal{F}_s]\\
& \{ \text{ since }B_s \text{ is }\mathcal{F}_s-\text{ measurable }\}\\
&= e^{a B_s} \mathbb{E}[e^{a (B_t - B_s)}|\mathcal{F}_s]\\
& \{ \text{ since }B_t - B_s \perp \mathcal{F}_s \}\\
&= e^{a B_s} \mathbb{E}[e^{a (B_t - B_s)}]\\
&= e^{a B_s} e^{\frac{1}{2}a^2(t-s)}
\end{align*}

This closes the proof. $\blacksquare$

An equivalent (but more symmetric) way to express the Markov property is to say that *the future of the process is independent of the past, when conditioned on the present*. Concretely, this means that for any $r < s< t$, we have that $X_t$ is independent of $X_r$, when we condition on $X_s$.

The conditional distribution of $X_t$ given $X_s$ is well described using *transition probabilities*. We will more interested in a case well these probabilities admit a density $f_{X_t|X_s=x}(y)$. More precisely, for such a Markov process, we have:

$$
\begin{align*}
\mathbb{E}[g(X_t)|X_s = x] &= \int_{\mathbb{R}} g(y) f_{X_t|X_s=x}(y) dy\\
&=\int_{\mathbb{R}} g(y) p_{s,t}(x,y) dy
\end{align*}
$$

Here, we explicitly write the left-hand side as a function of space, that is, the position $X_s$, by fixing $X_s = x$. In words, the *transition probability density* $p_{s,t}(x,y)$ represents the probability density that starting from $X_s = x$ at time $s$, the process ends up at $X_t = y$ at time $t > s$. If the process is time-homogenous, this only depends on the time difference $(t-s)$ and we write $p_{t-s}(x,y)$. From @eq-conditional-expectation-of-function-brownian-motion, we can write:
$$
\mathbb{E}[g(B_t)|B_s = x] = \int_{\mathbb{R}} g(u + x) \frac{e^{-\frac{u^2}{2(t-s)}}}{\sqrt{2\pi(t-s)}} du
$$

In the above expression, the random variable $B_t - B_s$ takes some value $u \in \mathbb{R}$ and $B_s = x$ is fixed. Then, $B_t$ takes the value $u + x$. Let $y = u + x$. Then, $u = y - x$. Consequently, we may write:

$$
\mathbb{E}[g(B_t)|B_s = x] = \int_{\mathbb{R}} g(y) \frac{e^{-\frac{(y-x)^2}{2(t-s)}}}{\sqrt{2\pi(t-s)}} dy
$$

So, the transition density function for standard Brownian motion is:

$$
p_s(x,y) = \frac{e^{-\frac{(y-x)^2}{2s}}}{\sqrt{2\pi s}}, \quad s>0, x,y\in\mathbb{R}
$$ {#eq-brownian-motion-transition-density-function}

This function is sometimes called the *heat kernel*, as it relates to the *heat equation*. 

The Markov property is very convenient to compute quantities, as we shall see throughout the chapter. As a first example, we remark that it is easy to express joint probabilities of a markov process $(X_t,t\geq 0)$ at different times. Consider the functions $f = \mathbf{1}_A$ and $g = \mathbf{1}_B$ from $\mathbb{R} \to \mathbb{R}$, where $A$ and $B$ are two intervals in $\mathbb{R}$. Let's compute $\mathbb{P}(X_{t_1} \in A, X_{t_2} \in B) = \mathbb{E}[\mathbf{1}_{A} \mathbf{1}_{B}] = \mathbb{E}[f(X_{t_1}) g(X_{t_2})]$ for $t_1 < t_2$. By the properties of conditional expectation and the Markov property, we have:

\begin{align*}
\mathbb{P}(X_{t_1} \in A, X_{t_2} \in B) &= \mathbb{E}[f(X_{t_1})g(X_{t_2})]\\
&= \mathbb{E}[f(X_{t_1})\mathbb{E}[g(X_{t_2})|\mathcal{F}_{t_1}]]\\
&= \mathbb{E}[f(X_{t_1})\mathbb{E}[g(X_{t_2})|X_{t_1}]]
\end{align*}

Assuming that the process is time-homogenous and admits a transition density $p_t(x,y)$ as for Brownian motion, this becomes:

\begin{align*}
\mathbb{P}(X_{t_1} \in A, X_{t_2} \in B) &= \int_{\mathbb{R}} f(x_1) \left(\int_{\mathbb{R}} g(x_2) p_{(t_2 - t1)}(x_1, x_2) dx_2 \right) p_{t_1}(x_0,x_1) dx_1\\
&= \int_{A} \left(\int_{B} p_{(t_2 - t_1)}(x_1, x_2) dx_2 \right) p_{t_1}(x_0,x_1) dx_1
\end{align*}

This easily generalizes to any finite-dimensional distribution of $(X_t, t\geq 0)$.

::: {#exm-markov-versus-martingale}

(Markov versus Martingale.) Martingales are not markov processes in general and markov processes are not martingales in general. There are processes such as brownian motion that enjoy both. An example of a markov process that is not a martingale is a Brownian motion with a drift $(X_t, t \geq 0)$, where $X_t = \sigma B_t + \mu t$. Conversely, take $Y_t = \int_0^t X_s dB_s$, where $X_s = \int_0^s B_u dB_u$. The integrand $X_s$ depends on whole Brownian motion path upto time $s$ and not just on $B_s$. 
:::

::: {#nte-functions-of-markov .callout-tip}

### Functions of Markov Processes

It might be tempting to think that if $(X_t,t\geq 0)$ is a Markov process, then the process defined by $Y_t = f(X_t)$ for some reasonable function $f$ is also Markov. Indeed, one could hope to write for an arbitrary bounded function $g$:

$$
\begin{align*}
\mathbb{E}[g(Y_t)|\mathcal{F}_s] = \mathbb{E}[g(f(X_t))|\mathcal{F}_s] = \mathbb{E}[g(f(X_t))|\mathcal{X}_s] 
\end{align*}
$$ {#eq-functions-of-markov-process}

by using the Markov property of $(X_t,t\geq 0)$. The flaw in this reasoning is that the Markov property should hold for the natural fitration $(\mathcal{F}_t^Y,t\geq 0)$ of the process $(Y_t,t\geq 0)$ and not the one of $(X_t,t\geq 0)$, $(\mathcal{F}_t^X,t\geq 0)$. It might be that the filtration $(\mathcal{F}_t^Y,t\geq 0)$ has less information that $(\mathcal{F}_t^X,t\geq 0)$, especially, if the function $f$ is not one-to-one. For example, if $f(x)=x^2$, then $\mathcal{F}_t^Y$ has less information than $\mathcal{F}_t^X$ as we cannot recover the sign of $X_t$ knowing $Y_t$. In other words, the second equality may not hold. In some cases, a function of a Brownian motion might be Markov, even when $f$ is not one-to-one. 
:::

It turns out that diffusions such as the Ornstein-Uhlenbeck process and the Brownian bridge are Markov processes.

::: {#thm-diffusions-are-markov-processes}

### Diffusions are Markov processes. 

Let $(B_t,t\geq 0)$ be a standard Brownian motion. Let $\mu : \mathbb{R} \to \mathbb{R}$ and $\sigma: \mathbb{R} \to \mathbb{R}$ be differentiable functions with bounded derivatives on $[0,T]$. Then, the diffusion with the SDE 

$$
dX_t = \mu(X_t) dt + \sigma(X_t)dB_t, \quad X_0 = x_0
$$

defines a time-homogenous markov process on $[0,T]$. 
:::

An analogous statement holds for time-inhomogenous diffusions. The proof is generalization of the Markov property of Brownian motion. We take advantage of the independence of Brownian increments. 

*Proof.*

By the [existence and uniqueness theorem](https://quantinsights.github.io/posts/ito-processes-and-stochastic-diff-eqs/#existence-and-uniqueness-of-sdes), this stochastic initial value problem(SIVP) defines a unique continous adapted process $(X_t,t\leq T)$. Let $(\mathcal{F}_t^X,t\geq 0)$ be the natural filtration of $(X_t,t\leq T)$. For a fixed $t > 0$, consider the process $W_s = B_{t+s} - B_t, s \geq 0$. Let $(\mathcal{F}_t,t \geq 0)$ be the natural filtration of $(B_t,t \geq 0)$. It turns out that the process $(W_s,s \geq 0)$ is a standard brownian motion independent of $\mathcal{F}_t$ (@exr-shifted-brownian-motion). For $s \geq 0$, we consider the SDE:

$$
dY_s = \mu (Y_s) ds + \sigma(Y_s) dW_s, \quad Y_0 = X_t
$$

Again by the [existence and uniqueness theorem](https://quantinsights.github.io/posts/ito-processes-and-stochastic-diff-eqs/#existence-and-uniqueness-of-sdes), there exists a unique solution to the SIVP that is adapted to the natural filtration of $W$. Note that, the shifted process $(X_{t+s},s\geq 0)$ is *the* solution to this SIVP since:

\begin{align*}
X_{t+s} &= X_{t} + \int_{t}^{t+s}\mu(X_u) du + \int_{t}^{t+s}\sigma(X_u) dB_u
\end{align*}

Perform a change of variable $v = u - t$. Then, $dv = du$, $dB_u = B(u_2) - B(u_1)= B(t + v_2) - B(t + v_1) = W(v_2) - W(v_1) = dW_v$. So,

\begin{align*}
X_{t+s} &= X_{t} + \int_{0}^{s}\mu(X_{t+v}) dv + \int_{0}^{s}\sigma(X_{t+v}) dW_v
\end{align*}

Let $Y_v= X_{t+v}$, $Y_0 = X_t$. Then,

\begin{align*}
Y_s &= Y_0 + \int_{0}^{s}\mu(Y_v) dv + \int_{0}^{s}\sigma(Y_v) dW_v
\end{align*}

Thus, we conclude that for any interval $A$:

$$
\mathbb{P}(X_{t+s} \in A|\mathcal{F}_t^X) = \mathbb{P}(Y_s \in A | \mathcal{F}_t^X)
$$

But, since $(Y_s,s \geq 0)$ depends on $\mathcal{F}_t^X$ only through $X_t$ (because $(W_s,s \geq 0)$ is independent of $\mathcal{F}_t$), we conclude that $\mathbb{P}(X_{t+s} \in A|\mathcal{F}_t^X) = \mathbb{P}(X_{t+s} \in A|X_t)$, so $(X_t,t \geq 0)$ is a time-homogenous markov process. $\blacksquare$

## The Strong Markov Property

The Doob's Optional Stopping theorem extended some properties of martingales to stopping times. The Markov property can also be extended to stopping times for certain processes. These processes are called *strong Markov processes*. 

We know, that the sigma-algebra $\mathcal{F}_t$ represents the set of all observable events upto time $t$. What is the sigma-algebra of observable events at a random stopping time $\tau$? 

::: {#def-sigma-algebra-of-the-past}

### $\sigma$-algebra of $\tau$-past

Let $(\Omega,\mathcal{F},\{\mathcal{F}_t\}_{t\geq 0},\mathbb{P})$ be a filtered probability space. The sigma-algebra at the stopping time $\tau$ is then:

$$
\mathcal{F}_{\tau} = \{A \in \mathcal{F}_\infty : A \cap \{\tau \leq t\} \in \mathcal{F}_t, \forall t \geq 0 \}
$$ {#eq-sigma-algebra-of-the-past}

:::

In words, an event $A$ is in $\mathcal{F}_\tau$, if we can determine if $A$ and $\{\tau \leq t\}$ both occurred or not based on the information $\mathcal{F}_t$ known at any arbitrary time $t$. You should be able to tell the value of the random variable $\mathbf{1}_A \cdot \mathbf{1}_{\{\tau \leq t\}}$ given $\mathcal{F}_t$ for any arbitrary time $t \geq 0$.

For example, if $\tau < \infty$, the event $\{B_\tau > 0\}$ is in $\mathcal{F}_\tau$. However, the event $\{B_1 > 0\}$ is not in $\mathcal{F}_\tau$ in general, since $A \cap \{\tau \leq t\}$ is not in $\mathcal{F}_t$ for $t < 1$. Roughly speaking, a random variable that is $\mathcal{F}_\tau$-measurable should be thought of as an explicit function of $X_\tau$. With this new object, we are ready to define the *strong markov property*.

::: {#def-strong-markov-property}

### Strong Markov Property

Let $(X_t,t\geq 0)$ be a stochastic process and let $(\mathcal{F}_t,t\geq 0)$ be its natural filtration. The process $(X_t,t\geq 0)$ is said to be *strong markov* if for any stopping time $\tau$ for the filtration of the process and any bounded function $g$:

$$
\mathbb{E}[g(X_{t+\tau})|\mathcal{F}_\tau] = \mathbb{E}[g(X_{t+\tau})|X_\tau]
$$

:::

This means that $X_{t+\tau}$ depends on $\mathcal{F}_\tau$ solely through $X_\tau$ (whenever $\tau < \infty$). It turns out that Brownian motion is a strong markov process. In fact a stronger statement holds which generalizes @exr-shifted-brownian-motion. 

::: {#thm-shifted-brownian-motion-about-a-stopping-time}

Let $\tau$ be a stopping time for the filtration of the Brownian motion $(B_t,t\geq 0)$ such that $\tau < \infty$. Then, the process:

$$
(B_{t+\tau} - B_{\tau},t\geq 0)
$$

is a standard brownian motion independent of $\mathcal{F}_\tau$.
:::

::: {#exm-brownian-motion-is-strong-markov}

(Brownian motion is strong Markov) To see this, let's compute the conditional MGF as in @eq-conditional-mgf-of-xt. We have:

$$
\begin{align*}
\mathbb{E}[e^{aB_{t+\tau}}|\mathcal{F}_\tau] &= \mathbb{E}[e^{a(B_{t+\tau} - B_\tau + B_\tau)}|\mathcal{F}_\tau]\\
&= e^{aB_\tau} \mathbb{E}[e^{a(B_{t+\tau} - B_\tau)}|\mathcal{F}_\tau]\\
& \{ B_\tau \text{ is }\mathcal{F}_\tau-\text{measurable }\}\\
&= e^{aB_\tau}\mathbb{E}[e^{a(B_{t+\tau} - B_\tau)}]\\
& \{ (B_{t+\tau} - B_\tau) \perp \mathcal{F}_\tau\}\\
&= e^{aB_\tau}e^{\frac{1}{2}a^2 t}\\
\end{align*}
$$

Thus, the conditional MGF is an explicit function of $B_\tau$ and $t$. This proves the proposition. $\blacksquare$
:::

*Proof* of @thm-shifted-brownian-motion-about-a-stopping-time.

We first consider for fixed $n$ the discrete valued stopping time:

$$
\tau_n = \frac{k + 1}{2^n}, \quad \text{ if } \frac{k}{2^n} \leq \tau < \frac{k+1}{2^n}, k\in \mathbb{N}
$$

In other words, if $\tau$ occurs in the interval $[\frac{k}{2^n},\frac{k+1}{2^n})$, we stop at the next dyadic $\frac{k+1}{2^n}$. By construction $\tau_n$ depends only on the process in the past. Consider the process $W_t = B_{t + \tau_n} - B_{\tau_n}, t \geq 0$. We show it is a standard brownian motion independent of $\tau_n$. This is feasible as we can decompose over the discrete values taken by $\tau_n$. More, precisely, take $E \in \mathcal{F}_{\tau_n}$, and some generic event $\{W_t \in A\}$ for the process $W$. Then, by decomposing over the values of $\tau_n$, we have:

$$
\begin{align*}
\mathbb{P}(\{W_t \in A\} \cap E) &= \sum_{k=0}^\infty \mathbb{P}\left(\{W_t \in A\} \cap E \cap \{\tau_n = \frac{k}{2^n}\}\right)\\
&= \sum_{k=0}^\infty \mathbb{P}\left(\{(B_{t+k/2^n} - B_{k/2^n}) \in A\} \cap E \cap \{\tau_n = \frac{k}{2^n}\}\right)\\
&= \sum_{k=0}^\infty \mathbb{P}\left(\{(B_{t+k/2^n} - B_{k/2^n}) \in A\}\right) \times \mathbb{P}\left( E \cap \{\tau_n = \frac{k}{2^n}\}\right)
\end{align*}
$$

since $(B_{t+k/2^n} - B_{k/2^n})$ is independent of $\mathcal{F}_{k/2^n}$ by @exr-shifted-brownian-motion and since $E \cap \{\tau_n = \frac{k}{2^n}\} \in \mathcal{F}_{k/2^n}$ by definition of stopping time. But, given $\{\tau_n = k/2^n\}$, the event $\{(B_{t+k/2^n} - B_{k/2^n}) \in A\}$ is the same as $\{B_t \in A\} = \{W_t \in A\}$, since this process is now a standard brownian motion. Thus, $\mathbb{P}\{(B_{t+k/2^n} - B_{k/2^n}) \in A\} = \mathbb{P}\{B_t \in A\} = \mathbb{P}\{W_t \in A\}$, dropping the dependence on $k$. The sum over $k$ then yields:

$$
\mathbb{P}\left(\{W_t \in A\}\cap E\right) = \mathbb{P}(W_t \in A) \mathbb{P}(E)
$$

as claimed. The extension to $\tau$ is done by using continuity of paths. We have:

$$
\lim_{n \to \infty} B_{t + \tau_n} - B_{\tau_n} = B_{t+\tau} - B_{\tau} \text{ almost surely}
$$

Note, that this only uses right continuity! Moreover, this implies that $B_{t+\tau} - B_\tau$ is independent of $\mathcal{F}_{\tau_n}$ for all $n$. Again by (right-)continuity this extends to independence of $\mathcal{F}_\tau$. The limiting distribution of the process is obtained by looking at the finite dimensional distributions of the increments of $B_{t+\tau_n} - B_{\tau_n}$ for a finite number of $t$'s and taking the limit as above. $\blacksquare$

Most diffusions also enjoy the strong markov property, as long as the functions $\sigma$ and $\mu$ encoding the volatility and drift are nice enough. This is the case for the diffusions we have considered. 

::: {#thm-most-diffusions-are-strong-markov}

### Most diffusions are strong markov

Consider a diffusion $(X_t,t\leq T)$ as as in @thm-diffusions-are-markov-processes. Then, the diffusion has strong markov property. 
:::

The proof follows the line of the one of @thm-diffusions-are-markov-processes

*Proof.*

Consider the time-homogenous diffusion:

$$
dX_t = \mu(X_t)dt + \sigma(X_t)dB_t
$$

By the [existence and uniqueness theorem](https://quantinsights.github.io/posts/ito-processes-and-stochastic-diff-eqs/#existence-and-uniqueness-of-sdes), this SIVP defines a unique continuous adapted process $(X_t,t \geq 0)$. Let $\mathfrak{F}=(\mathcal{F}_t^X,t \geq 0)$ be the natural filtration of $(X_t, t\leq T)$. Let $\tau$ be a stopping time for the filtration $\mathfrak{F}$ and consider the process $W_t = B_{t+\tau} - B_\tau$. From @thm-shifted-brownian-motion-about-a-stopping-time, we know that the process $(W_t,t\geq 0)$ is a standard brownian motion independent $\mathcal{F}_\tau$. For $s \geq 0$, we consider the SDE:

$$
dY_s = \mu(Y_s)ds + \sigma(Y_s)dW_s, \quad Y_0 = X_\tau
$$ {#eq-diffusion-of-Y}

Again by the [existence and uniqueness theorem](https://quantinsights.github.io/posts/ito-processes-and-stochastic-diff-eqs/#existence-and-uniqueness-of-sdes), there exists a unique solution to the SIVP that is adapted to the natural filtration of $W$. We claim that $(X_{s+\tau},s \geq 0)$ is the solution to this equation, since:

$$
X_{s+\tau} = X_\tau + \int_\tau^{s+\tau} \mu(X_u)du + \int_{\tau}^{s+\tau} \sigma(X_u)dB_u
$$

Perform a change of variable $v = u - \tau$. Then, the limits of integration bare, $v = 0$ and $v = s$. And $dv = du$. 

$dB_u  \approx B_{u_2} - B_{u_1} = B(v_1 + \tau) - B(v_2 + \tau) = W(v_2) - W(v_1) =dW_v$. 

$$
X_{s+\tau} = X_\tau + \int_0^{s} \mu(X_{v+\tau})dv + \int_{0}^{s} \sigma(X_{v+\tau})dW_v
$$

If we let $Y_0 = X_\tau$, $Y_v = X_{v+\tau}$, we recover the dynamics of $(Y_v,v \geq 0)$ in @eq-diffusion-of-Y. So, $(X_{s+\tau},s\geq 0)$ is the solution to the SIVP in @eq-diffusion-of-Y. Thus, we conclude for any interval $A$:

$$
\mathbb{P}(X_{s+\tau} \in A | \mathcal{F}_\tau^X) = \mathbb{P}(Y_v \in A| \mathcal{F}_\tau^X)
$$

But, since $(Y_v,v\geq 0)$ depends on $\mathcal{F}_\tau^X$ only through $X_\tau$, we conclude that $\mathbb{P}(X_{s + \tau} \in A | \mathcal{F}_\tau^X) = \mathbb{P}(X_{s + \tau} \in A| X_\tau)$. Consequently, $(X_t,t \geq 0)$ is a strong-markov process. $\blacksquare$

::: {#nte-extension-of-optional-sampling .callout-tip}

### Extension of optional sampling

Consider a continuous martingale $(M_t, t\leq T)$ for a filtration $(\mathcal{F}_t, t\geq 0)$ and a stopping time $\tau$ for the same filtration. Suppose we would like to compute for some $T$:

$$
\mathbb{E}[M_T \mathbf{1}_{\{\tau \leq T\}}]
$$

It would be tempting to condition on $\mathcal{F}_\tau$ and write $\mathbb{E}[M_T |\mathcal{F}_\tau] = M_\tau$ on the event $\{\tau \leq T\}$. We would then conclude that:

$$
\mathbb{E}[M_T 1_{\{\tau \leq T\}}] = \mathbb{E}[1_{\{\tau \leq T\}} \mathbb{E}[M_T|\mathcal{F}_\tau] ] = \mathbb{E}[M_\tau 1_{\{\tau \leq T\}}]
$$

In some sense, we have extended the martingale property to stopping times. This property can be proved under reasonable assumptions on $(M_t,t\leq T)$ (for example, if it is positive). Indeed, it suffices to approximate $\tau$ by discrete valued stopping time $\tau_n$ as in the proof of @thm-shifted-brownian-motion-about-a-stopping-time. One can then apply martingale property at a fixed time. 
:::

## Kolmogorov's equations

We look at more detail on how PDEs come up when computing quantities related to Markov processes.

::: {#exm-heat-equation-and-brownian-motion}

(Heat Equation and Brownian motion) Let $f(t,x)$ be a function of time and space. The heat equation in $1+1$-dimension (one dimension of time, one dimension of space) is the PDE:

$$
\begin{align*}
\frac{\partial f}{\partial t} &= \frac{1}{2}\frac{\partial^2 f}{\partial x^2}
\end{align*}
$$ {#eq-heat-equation-in-2d}

In $1+d$ (one dimension of time, $d$ dimensions of space), the heat equation is:

$$
\begin{align*}
\frac{\partial f}{\partial t} &= \frac{1}{2}\nabla^2 f
\end{align*}
$$ {#eq-heat-equation-in-d-plus-one-dims}

where $\nabla^2$ is the Laplacian operator. Note that this PDE differs from the [martingale condition](https://quantinsights.github.io/posts/multivariate_ito_calculus/#eq-martingale-condition-for-f) for $f(t,B_t)$ by a minus sign. This is explained in more detail below. For now, we notice that solutions to this PDE can be expressed as an expectation over Brownian paths (in the same spirit as in the Dirichlet problem). 

:::

## Numerical Projects

## Exercises

::: {#exr-shifted-brownian-motion}

(Shifted Brownian Motion) Let $(B_t,t\geq 0)$ be a standard brownian motion. Fix $t > 0$. Show that the process $(W_s,s \geq 0)$ with $W_s = B_{t+s} - B_t$ is a standard brownian motion independent of $\mathcal{F}_t$.
:::

*Solution*.

At $s = 0$, $W(0) = B(t) - B(t) = 0$. 

Consider any arbitrary times $t_1 < t_2$. We have:

\begin{align*}
W(t_2) - W(t_1) &= (B(t + t_2) - B(t)) - (B(t + t_1) - B(t))\\
&= B(t + t_2) - B(t + t_1)
\end{align*}

Now, $B(t + t_2) - B(t + t_1) \sim \mathcal{N}(0,t_2 - t_1)$. So, $W(t_2) - W(t_1)$ is a Gaussian random variable with mean $0$ and variance $t_2 - t_1$.

Finally, consider any finite set of times $0=t_0 < t_1 < t_2 < \ldots < t_n = T$. Then, $t < t + t_1 < t + t_2 < \ldots < t + t_n$. We have that, $B(t + t_1) - B(t)$, $B(t + t_2) - B(t + t_1)$, $B(t + t_3) - B(t + t_2)$, $\ldots$, $B(t+T) - B(t+t_{n-1})$ are independent random variables. Consequently, $W(t_1) - W(0)$, $W(t_2) - W(t_1)$, $W(t_3) - W(t_2)$, $\ldots$, $W(t_n) - W(t_{n-1})$ are independent random variables. So, $(W_s,s\geq 0)$ is a standard brownian motion.

Also, we have:

\begin{align*}
\mathbb{E}[W(s)|\mathcal{F}_t] &= \mathbb{E}[B(t + s) - B(t)|\mathcal{F}_t]\\
& \{ B(t+s) - B(t) \perp \mathcal{F}_t \}\\
&= \mathbb{E}[B(t + s) - B(t)]\\
&= \mathbb{E}[W(s)]
\end{align*}

Thus, $W(s)$ is independent of $\mathcal{F}_t$, it does not depend upon the information available upto time $t$.

