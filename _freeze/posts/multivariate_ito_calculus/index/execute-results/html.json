{
  "hash": "6fbca5d484406f2f5ebd5614a5c5d8b6",
  "result": {
    "markdown": "---\ntitle: \"Multivariate Ito Calculus\"\nauthor: \"Quasar\"\ndate: \"2024-07-04\"\ncategories: [Stochastic Calculus]      \nimage: \"image.jpg\"\ntoc: true\ntoc-depth: 3\n---\n\n# Multivariate Ito Calculus.\n\nWe can generalize the theory to functions of several brownian motions. This unleashes the full power of Ito calculus.\n\n## Multidimensional Brownian motion.\n\n::: {#def-brownian-motion-in-Rd}\n### Brownian motion in $\\mathbf{R}^{d}$. \n\nTake $d\\in\\mathbf{N}$. Let $B^{(1)},\\ldots,B^{(d)}$ be independent standard Brownian motions in $(\\Omega,\\mathcal{F},\\mathbb{P})$. The process $(B_{t}:t\\geq0)$ taking values in $\\mathbf{R}^{d}$ defined by :\n\n\\begin{aligned}\nB_{t} & =(B_{t}^{(1)},\\ldots,B_{t}^{(d)}),\\quad t\\geq0\n\\end{aligned}\n\nis called a $d-$dimensional Brownian motion or a Brownian motion in $\\mathbf{R}^{d}$.\n:::\n\nThe Brownian filtration $(\\mathcal{F}_{t}:t\\geq0)$ is now composed of the information of all Brownian motions. In other words, it is given by the sigma-fields:\n\n\\begin{aligned}\n\\mathcal{F}_{t} & =\\sigma(B_{s}^{(i)},1\\leq i\\leq d,s\\leq t)\n\\end{aligned}\n\nFor every outcome $\\omega$, the path of trajectory of a $d-$dimensional Brownian motion is a curve in space parametrized by the time $t$:\n\n\\begin{aligned}\nt\\mapsto B_{t}(\\omega) & =(B_{t}^{(1)}(\\omega),B_{t}^{(2)}(\\omega),\\ldots,B_{t}^{(d)}(\\omega))\n\\end{aligned}\n\nOf course, this curve is continuous, since each coordinate is. The below numerical project gives an example of one path of a two-dimensional brownian motion. This is a very rugged and intertwined curve! We might wonder, what it does as $t\\to\\infty$. Does it wander around $(0,0)$ ad infinitum or does it eventually escape to infinity? We will answer this question in a later section. For doing so, we shall need a version of Ito's formula for multi-dimensional Brownian motion. We finish this section by noticing that it is also easy to construct Brownian motions in higher dimensions for which the coordinates are correlated.\n\n### 2D Brownian Motion \n\nConsider a two-dimensional Brownian motion $(B_{t}^{(1)},B_{2}^{(2)})$ starting at $(0,0)$.\n\nLet's plot one path of this Brownian motion on the plane $\\mathbf{R}^{2}$ on the plane in $\\mathbf{R}^{2}$ on the time interval $[0,5]$ using a discretization of $0.001$.\n\nWe define `BrownianMotion2D` class.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\n\nclass BrownianMotion2D:\n    \"\"\"\n    Generate sample paths for a 2d-brownian motion\n    \"\"\"\n    def __init__(\n        self,\n        endpoint : float = 1.0,\n        discretization : float = 0.01\n    ):\n        self.endpoint = endpoint\n        self.discretization = discretization\n\n    def generate_paths(self, num_paths : int):\n        steps = int(self.endpoint/self.discretization)\n        delta_z = np.sqrt(self.discretization) * np.random.randn(num_paths,2,steps)\n        \n        # paths has shape [num_paths,2,num_steps]\n        paths = np.cumsum(delta_z,axis=2)\n\n        # Brownian motion has position (0,0) at time t=0\n        # Append initial position \n        init_position = np.zeros((num_paths,2,1))\n        paths = np.append(init_position,paths,axis=2)\n\n        return paths\n```\n:::\n\n\nWe can then configure and use `BrownianMotion2D` objects as we please.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\nbm = BrownianMotion2D(endpoint=5.0,discretization=0.001)\npaths = bm.generate_paths(num_paths=1)\npath = paths[0]\n\n\nplt.xlabel(r'$x$')\nplt.ylabel(r'$y$')\nplt.title(r'2D-Brownian motion')\nplt.grid(True)\nplt.plot(path[0],path[1],linewidth=1,color='blue')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-3-output-1.png){width=594 height=447}\n:::\n:::\n\n\n### Brownian motion with correlated coordinates\n\n::: {#exm-brownian-motion-with-correlated-coordinates}\n### Brownian motion with correlated coordinates\nLet $(B_{t}:t\\geq0)$ be a two dimensional brownian motion. Let $-1<\\rho<1$. We construct the two dimensional process as follows: $W_{t}=(W_{t}^{(1)},W_{t}^{(2)})$ where:\n                                                           \n\\begin{aligned}\nW_{t}^{(1)} & =B_{t}^{(1)}\\\\\nW_{t}^{(2)} & =\\rho B_{t}^{(1)}+\\sqrt{1-\\rho^{2}}B_{t}^{(2)}\n\\end{aligned}\n\n$W_{t}^{(1)}=B_{t}^{(1)}$ is Gaussian with mean $0$ and variance $t$. Since, $B_{t}^{(1)}$ and $B_{t}^{(2)}$are independent gaussian random variables and the sum of IID Gaussians is Gaussian, $W_{t}^{(2)}$ is Gaussian with mean $0$ and variance $t$. The covariance between\n$W_{t}^{(1)}$ and $W_{t}^{(2)}$ is:\n\n\\begin{aligned}\n\\mathbf{E}[W_{t}^{(1)}W_{t}^{(2)}] & =\\mathbf{E}[B_{t}^{(1)}(\\rho B_{t}^{(1)}+\\sqrt{1-\\rho^{2}}B_{t}^{(2)})]\\\\\n & =\\mathbf{E}[\\rho(B_{t}^{(1)})^{2}+\\sqrt{1-\\rho^{2}}B_{t}^{(1)}B_{t}^{(2)}]\\\\\n & =\\rho t\n\\end{aligned}\n\nHence, the coordinates at time $t$ are not independent.\n:::\n\nConsider now the process $(W_{t}:t\\geq0)$ for $\\rho=1/2$ as in example 2. Let's plot one path of this process on the plane $\\mathbf{R}^{2}$ on the time-interval $[0,5]$ using a discretization of $0.001$.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nclass BrownianMotion2DWithCorrelatedCoords(BrownianMotion2D):\n    \"\"\"\n    Generate sample paths for a 2d-brownian motion\n    have correlated coordiantes\n    \"\"\"\n\n    def __init__(\n        self, \n        endpoint: float = 1.0, \n        discretization: float = 0.01, \n        rho: float = 0.0\n    ):\n        self.endpoint = endpoint\n        self.discretization = discretization\n        self.rho = rho\n\n    def generate_paths(self, num_paths: int):\n\n        # Call the base class generate_paths() method to generate a pair of\n        # independent brownian motion paths. It returns a tensor of\n        # shape (num_paths, 2, num_steps)\n        paths = super().generate_paths(num_paths=num_paths)\n\n        # Extract the brownian motions B1(t) and B2(t)\n        # B1(t) and B2(t) have dimensions [num_paths,num_steps]\n        x_coord = paths[:, 0, :]\n        y_coord = paths[:, 1, :]\n\n        # Apply the transformation\n        # W1(t) = B1(t)\n        # W2(t) = rho * B1(t) + sqrt(1 - rho**2) B2(t)\n        x_coord = x_coord\n        y_coord = self.rho * x_coord + np.sqrt(1 - self.rho**2) * y_coord\n\n        # Assemble back the x- and y- coordinates\n        x_coord = np.expand_dims(x_coord, axis=1)\n        y_coord = np.expand_dims(y_coord, axis=1)\n\n        # Return a tensor of shape [num_paths,d=2,num_steps]\n        return np.concatenate([x_coord, y_coord], axis=1)\n```\n:::\n\n\nLet's configure the `BrownianMotion2DWithCorrelatedCoords` engine with the settings `endpoint=5.0`, `discretization=0.001` and `rho=0.5` and generate a sample path.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\nbm = BrownianMotion2DWithCorrelatedCoords(\n    endpoint=5.0,\n    discretization=0.001,\n    rho=0.50\n)\npaths = bm.generate_paths(num_paths=1)\npath = paths[0]\n\nplt.xlabel(r'$x$')\nplt.ylabel(r'$y$')\nplt.title(r'Correlated Brownian motion $W(t)=(W^{(1)}(t),W^{(2)}(t))$')\nplt.grid(True)\nplt.plot(path[0],path[1],linewidth=1,color='blue')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-1.png){width=582 height=452}\n:::\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\nplt.xlabel(r'$t$')\nplt.ylabel(r'$W_t$')\nplt.title(r'Correlated Brownian motion paths')\nplt.grid(True)\nt = np.linspace(0.0,stop=5.0,num=5001)\nplt.plot(t,path[0],linewidth=0.75)\nplt.plot(t,path[1],linewidth=0.75)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-1.png){width=584 height=447}\n:::\n:::\n\n\n## Ito's Formula.\n\n::: {#thm-ito-formula-function-of-d-brownian-motions}\n### Ito's Formula. \n\nLet $(B_{t}:t\\geq0)$ be a $d-$dimensional brownian motion. Consider $f\\in\\mathcal{C}^{2}(\\mathbf{R}^{d})$. Then, we have with probability one that for all $t\\geq0$:\n\n\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\sum_{i=1}^{d}\\int_{0}^{t}\\partial_{x_{i}}f(B_{s})dB_{s}^{(i)}+\\frac{1}{2}\\int_{0}^{t}\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(B_{s})ds\\label{eq:multidimensional-ito-formula}\n\\end{aligned}\n\n:::\n\n\n::: {#rem-equality-of-processes} \nI stress that, as in the one-dimensional case, Ito's formula is an equality of processes (and not an equality in distribution). Thus, the processes on both sides must agree for each path. \n:::\n\nInterestingly, the mixed partials $\\partial_{x_{i}x_{j}}f(B_{s})$, $i\\neq j$ do not appear in the formula! We see from Ito's formula that the process $f(B_{t})$ can be represented as a sum of $d+1$ processes: $d$ Ito integrals and one Riemann integral (which is a process of finite variation). In vector notation, the formula takes the form:\n\n\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\int_{0}^{t}\\nabla f(B_{s})^{T}dB_{s}+\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}f(B_{s})ds\n\\end{aligned}\n\nwhere it is understood that the first term is the sum of the $d$ Ito integrals in the equation. The symbol $\\nabla^{2}$ is the Laplacian of $f$:\n\n$\\sum_{i=1}^{d}\\frac{\\partial^{2}}{\\partial x_{i}^{2}}f(B_{s}^{(1)},\\ldots,B_{s}^{(d)})ds$\n\nIn differential form, Ito's formula becomes very neat:\n\n\\begin{aligned}\ndf(B_{t}) & =\\sum_{i=1}^{d}\\partial_{x_{i}}f(B_{s})dB_{t}^{(i)}+\\frac{1}{2}\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(B_{s})dt=\\nabla f(B_{t})^{T}dB_{s}+\\frac{1}{2}\\nabla^{2}f(B_{t})dt\n\\end{aligned}\n\n\n::: {#exm-ito-formula-1}\nConsider the functions (1) $f(x_{1},x_{2})=x_{1}^{2}+x_{2}^{2}$ (2) $f(x_{1},x_{2})=e^{x_{1}}\\cos x_{2}$ and the processes $(X_{t}:t\\geq0)$ and $(Y_{t}:t\\geq0)$. If we apply Ito's formula to the first process, we have:\n\n\\begin{aligned}\nX_{t} & =\\int_{0}^{t}2B_{s}^{(1)}dB_{s}^{(1)}+\\int_{0}^{t}2B_{s}^{(2)}dB_{s}^{(2)}+\\frac{1}{2}\\int_{0}^{t}(4dt)\\\\\n & =\\int_{0}^{t}2B_{s}^{(1)}dB_{s}^{(1)}+\\int_{0}^{t}2B_{s}^{(2)}dB_{s}^{(2)}+2t\n\\end{aligned}\n\nThe second process gives:\n\n\\begin{aligned}\nY_{t} & =\\cos B_{s}^{(2)}\\int_{0}^{t}e^{B_{s}^{(1)}}dB_{s}^{(1)}-e^{B_{s}^{(1)}}\\int\\sin B_{s}^{(2)}dB_{s}^{(2)}+\\frac{1}{2}\\int_{0}^{t}\\left(e^{B_{s}^{(1)}}\\cos B_{s}^{(2)}-e^{B_{s}^{(1)}}\\cos B_{s}^{(2)}\\right)dt\\\\\n & =1+\\cos B_{s}^{(2)}\\int_{0}^{t}e^{B_{s}^{(1)}}dB_{s}^{(1)}-e^{B_{s}^{(1)}}\\int\\sin B_{s}^{(2)}dB_{s}^{(2)}\n\\end{aligned}\n:::\n\n::: {#exm-cross-variation-of-b1-and-b2}\n (Cross-Variation of $B_{t}^{(1)}$ and $B_{t}^{(2)}$). Let $(t_{j}:j\\leq n)$ be a sequence of partitions of $[0,t]$ such that $\\max_{j}|t_{j+1}-t_{j}|\\to0$ as $n\\to\\infty$. Prove that:\n\n\\begin{aligned}\n\\lim_{n\\to\\infty}\\sum_{j=0}^{n-1}(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)}) & =0\\quad\\text{in } L^{2}\n\\end{aligned}\n\nThis justifies the rule $dB_{t}^{(1)}\\cdot dB_{t}^{(2)}=0$.\n\n*Hint*: Just compute the second moment of the sum.\n:::\n\n::: {#sol-solution-1}\nWe have:\n\n\\begin{aligned}\n & \\mathbf{E}\\left[\\left(\\sum_{j=0}^{n-1}(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})\\right)^{2}\\right]\\\\\n= & \\sum_{j=0}^{n-1}\\mathbf{E}[(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})^{2}(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})^{2}]\\\\\n+ & 2\\sum_{j<k}\\mathbf{E}\\left[(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{k+1}}^{(1)}-B_{t_{k}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})(B_{t_{k+1}}^{(2)}-B_{t_{k}}^{(2)})\\right]\n\\end{aligned}\n\nBoth these expectations are zero, since the brownian motions are independent and non-overlapping increments are independent.\n\nConsequently,\n$\\sum_{j=0}^{n-1}(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})\\to0$ in the $L^{2}$ sense.\n:::\n\n::: {.proof}\nThe proof of the formula follows the usual recipe: Taylor's theorem together with the quadratic variation and the cross-variation. In this case, we do get a cross-variation between the different Brownian motions. More precisely, consider a partition $(t_{j}:j\\leq n)$ of $[0,t]$. Then we can write:\n\n\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\sum_{j=0}^{n-1}(f(B_{t_{j+1}})-f(B_{t_{j}}))\n\\end{aligned}\n\nWe can apply the Taylor's series expansion for each $j$ to get:\n\n\\begin{aligned}\nf(B_{t})-f(B_{0}) & =\\sum_{j=0}^{n-1}\\nabla f(B_{t_{j}})(B_{t_{j+1}}-B_{t_{j}})\\\\\n & +\\frac{1}{2}\\sum_{j=0}^{n-1}(B_{t_{j+1}}-B_{t_{j}})^{T}Hf(B_{t_{j}})(B_{t_{j+1}}-B_{t_{j}})+\\mathcal{E}\n\\end{aligned}\n\nwhere $Hf$ is the Hessian matrix of $f$. We wrote the expansion using the vector notation to be economical. Let's keep in mind that each term is a sum over the derivatives. The first term will converge to $d$ Ito integrals as in the one-dimensional case. Now, the summand in the second\nterm is:\n\n$$(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)},\\ldots,B_{t_{j+1}}^{(d)}-B_{t_{j}}^{(d)})\\left[\\begin{array}{ccc}\n\\partial_{x_{1}}^{2}f(B_{t_{j}}) & \\ldots & \\partial_{x_{1}x_{d}}^{2}f(B_{t_{j}})\\\\\n\\vdots & \\ddots\\\\\n\\partial_{x_{d}x_{1}}^{2}f(B_{t_{j}}) &  & \\partial_{x_{d}}^{2}f(B_{t_{j}})\n\\end{array}\\right]\\left[\\begin{array}{c}\nB_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)}\\\\\n\\vdots\\\\\nB_{t_{j+1}}^{(d)}-B_{t_{j}}^{(d)}\n\\end{array}\\right]$$\n\nSo, $(B_{t_{j+1}}^{(i)}-B_{t_{j}}^{(i)})$ is pre-multiplied with the term $\\partial_{x_{i}x_{k}}^{2}f(B_{t_{j}})$ and it is post-multiplied $(B_{t_{j+1}}^{(k)}-B_{t_{j}}^{(k)})$. Consequently, the second term in the Taylor's series expansion can be re-written as:\n\n$$\\sum_{j=0}^{n-1}\\left(\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(B_{t_{j}})(B_{t_{j+1}}^{(i)}-B_{t_{j}}^{(i)})^{2}+\\sum_{1\\leq i<k\\leq d}\\partial_{x_{i}x_{k}}^{2}f(B_{t_{j}})(B_{t_{j+1}}^{(i)}-B_{t_{j}}^{(i)})(B_{t_{j+1}}^{(k)}-B_{t_{j}}^{(k)})\\right)$$\n\nThe second term on the right converges to $0$ in the $L^{2}$ sense when\n$i\\neq k$, from exercise. This explains why the mixed derivatives disappear in the multi-dimensional Ito's formula. As for the case $i=k$, it reduces to the quadratic variation as in the one-dimensional case. This is where the Riemann integral arises, after suitable conditioning on $\\mathcal{F}_{t_{j}}$, the sigma-field generated by $B_{s}$, $s\\leq t_{j}$. \n:::\n\n\nAs in the one-dimensional case,it is not necessary to learn Ito's formula by heart. It suffices to write the differential of the function $f$ to second order. We can then apply the rules of multivariate Ito calculus:\n\n      $\\cdot$       $dt$   $dB_{t}^{(1)}$   $dB_{t}^{(2)}$   $\\ldots$\n  ---------------- ------ ---------------- ---------------- ----------\n        $dt$        $0$         $0$              $0$           $0$\n   $dB_{t}^{(1)}$   $0$         $dt$             $0$           $0$\n   $dB_{t}^{(2)}$   $0$         $0$              $dt$          $0$\n      $\\ldots$      $0$         $0$              $0$           $dt$\n\nNote that the rule $dB_{t}^{(i)}dB_{t}^{(j)}=0$ for $i\\neq j$ is being\nmotivated by the cross-variation result.\n\nHow can we construct martingales using the Ito's formula? Recall that an Ito integral $(\\int_{0}^{t}X_{s}dB_{s},t\\leq T)$ is a martingale whenever the integrand is in $\\mathcal{L}_{c}^{2}(T)$, the space of adapted processes with continuous paths and for which:\n\n\\begin{aligned}\n\\int_{0}^{T}\\mathbf{E}[X_{s}^{2}]ds & <\\infty\n\\end{aligned}\n\nThe only difference here is that the integrand is a function of many Brownian motions. However, the integrands involved in the Ito integrals of the multidimensional Ito's formula are clearly adapted to the filtration $(\\mathcal{F}_{t}:t\\geq0)$ of $(B_{t}:t\\geq0)$ as they are functions of the Brownian motion at the time. The arguments of Ito\nintegral in and apply verbatim, if we take the definition of $\\mathcal{L}_{c}^{2}(t)$ with the filtration $(\\mathcal{F}_{t}:t\\geq0)$ of $(B_{t}:t\\geq0)$. With this in mind, we have the following corollary.\n\n### Brownian Martingales\n\n::: {#cor-brownian-martingales}\n### Brownian Martingales. \n\nLet $(B_{t}:t\\geq0)$ be a Brownian motion in $\\mathbf{R}^{d}$. Consider $f\\in\\mathcal{C}^{2}(\\mathbf{R}^{d})$ such that processes $(\\partial_{x {i}}f(B_{t}),t\\leq T)\\in\\mathcal{L}_{c}^{2}(T)$ for every $i\\leq d$. Then, the process :\n\n$$f(B_{t})-\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}f(B_{s})ds,\\quad t\\leq T$$\n\nwhere $\\nabla^{2}=\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}$ is the Laplacian, is a martingale for the Brownian filtration.\n:::\n\nFor example, consider the processes $X_{t}=(B_{t}^{(1)})^{2}+(B_{t}^{(2)})^{2}$ and $Y_{t}=\\exp(B_{t}^{(1)})\\cos(B_{t}^{(2)})$. Then, we have :\n\n$$\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}X_{s}ds=\\frac{1}{2}\\int_{0}^{t}4ds=2t$$\n\nand\n\n\\begin{aligned}\n\\frac{1}{2}\\int_{0}^{t}\\nabla^{2}Y_{s}ds & =\\frac{1}{2}\\int_{0}^{t}0\\cdot ds=0\n\\end{aligned}\n\nThus, the processes $X_{t}-2t$ and $Y_{t}$ are martingales for the Brownian filtration. In one dimension, there are no interesting martingales constructed with functions of *space* only. Indeed, $(f(B_{t}):t\\geq0)$ is a martingale if and only if $f''(x)=0$ for all $x$. But, such functions are of the form $f(x)=ax+b$, $a,b\\in\\mathbf{R}$. In other words, in one dimension, Brownian martingales of the form $f(B_{t})$ are simply $aB_{t}+b$. Not very surprising! The situation is very different in higher dimensions. Indeed, corollary implies that $f(B_{t})$ is a martingale whenever $f$ is a harmonic function:\n\n::: {#def-harmonic-function}\n### Harmonic function.\n\nA function $f:\\mathbf{R}^{d}\\to\\mathbf{R}$ is harmonic in $\\mathbf{R}^{d}$ if and only if $\\nabla^{2}f(x)\\equiv0$ for all $x\\in\\mathbf{R}^{d}$. More generally, a function $f:\\mathbf{R}^{d}\\to\\mathbf{R}$ is harmonic in the region $\\mathcal{O}\\subset\\mathbf{R}^{d}$ if and only if $\\nabla^{2}f(x)\\equiv0$ for all $x\\in\\mathcal{O}$.\n:::\n\nNote that the function $f(x)=e^{x_{1}}\\cos x_{2}$ is harmonic in $\\mathbf{R}^{d}$. This is why the process $Y_{t}=\\exp(B_{t}^{(1)})\\cos(B_{t}^{(2)})$ is a martingale. The distinction to a subset of $\\mathbf{R}^{d}$ in the above definition is important since it may happen that the function is harmonic only in a subset of the space; see for example equation. It is possible to define a Brownian martingale in such cases by considering the process until it exits the region. This will turn out to be important as we move ahead.\n\nThe multidimensional Ito's formula generalizes to functions of time and space as in proposition:\n\n::: {#def-function-in-C12} \nA function $f:[0,\\infty)\\times\\mathbf{R}^{d}\\to\\mathbf{R}$ is in $\\mathcal{C}^{1,2}([0,T]\\times\\mathbf{R}^{d})$ if the partial derivative in *time* :\n\n$$\\frac{\\partial}{\\partial t}f(t,\\mathbf{x})$$\n\nexists and is continuous and the second order partial derivatives in space:\n\n$$\\frac{\\partial^{2}}{\\partial x_{i}^{2}}f(t,x_{1},x_{2},\\ldots,x_{i},\\ldots,x_{d}),\\quad1\\leq i\\leq d$$\n\nexist and are continuous.\n:::\n\n## Multidimensional Ito formula - Functions of space and time\n\n::: {#thm-Multidimensional-Ito-formula-functions-of-space-and-time} \n### Multidimensional Ito's formula for functions of space and time\n\nLet $(B_{t}:t\\leq T)$ be a $d$-dimensional Brownian motion. Consider a function $f\\in\\mathcal{C}^{1,2}([0,T]\\times\\mathbf{R}^{d})$. Then, we have with\nprobability one for all $t\\leq T$:\n\n\\begin{aligned}\nf(t,B_{t})-f(0,B_{0}) & =\\sum_{i=1}^{d}\\int_{0}^{t}\\partial_{x_{i}}f(s,B_{s})dB_{s}^{(i)}+\\int_{0}^{t}\\left(\\partial_{t}f(s,B_{s})+\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(s,B_{s})\\right)ds\n\\end{aligned}\n:::\n\nThe martingale condition is then similar to the ones in corollary ([\\[cor:brownian-martingales-in-Rd\\]](#cor:brownian-martingales-in-Rd){reference-type=\"ref\" reference=\"cor:brownian-martingales-in-Rd\"}): if the processes $(\\partial_{x_{i}}f(s,B_{s}),t\\leq T)\\in\\mathcal{L}_{c}^{2}(T)$ for every $1\\leq i\\leq d$, then the process\n\n$$f(t,B_{t})-\\int_{0}^{t}\\left\\{ \\partial_{t}f(s,B_{s})++\\sum_{i=1}^{d}\\partial_{x_{i}}^{2}f(s,B_{s})\\right\\} ds,\\quad t\\leq T$$ {#eq-martingale-process}\n\nis a martingale for the Brownian filtration. In particular, if $f$ satisfies the partial differential equation:\n\n$$\n\\begin{aligned}\n\\frac{\\partial f}{\\partial t}+\\frac{1}{2}\\nabla^{2}f & =0\n\\end{aligned}\n$$ {#eq-martingale-condition-for-f}\n\nthen the process $(f(t,B_{t}):t\\leq T)$ itself is a martingale.\n\n## Polya's Random Walk Theorem\n\nConsider a *simple random walk* on the integer lattice $\\mathbb{Z}^d$. At each time step, a random walker makes a random move of length one in one of the lattice directions.\n\nWe say that, if the random walk returns to the origin with probability one infinitely many times, it is *recurrent*, if it does not we will call it *transient*. \n\nIt's worth to spend a moment visiting Polya's Random Walk Theorem, a fascinating, but not so intuitive result.\n\nAssuming all random walks start at the origin, we define $u$ to be the probability that a random walker returns to the origin. The probability that the random walker returns to the origin exactly $m$ times is:\n\n\\begin{align*}\n{m \\choose m-1} u^{m-1} (1 - u)^{m - (m - 1)} = u^{m-1}(1-u)\n\\end{align*}\n\nThe expected number of times the particle returns to the origin for an infinite random walk is:\n\n\\begin{align*}\nE &= \\sum_{m = 1}^{\\infty} m (u^{m-1}(1-u))\\\\\n&= (1-u)\\sum_{m=1}^{\\infty}mu^{m-1}\\\\\n&= (1-u)\\sum_{m=1}^{\\infty}\\frac{d}{du}u^{m}\\\\\n\\end{align*}\n\nWe note that limit exchanging is acceptable since the power series $\\sum_{n=1}^{\\infty}x^n$ converges uniformly for $u < 1$ and we can apply the differentiable limit theorem.\n\nSo we obtain:\n\n\\begin{align*}\nE &= (1-u)\\frac{d}{du}\\sum_{m = 1}^{\\infty} u^m \\\\\n&= (1-u)\\cdot \\frac{1}{(1-u)^2}\\\\\n&= \\frac{1}{1-u}\n\\end{align*}\n\nSo, we see that if $E$ is finite, $u < 1$, then the walk is transient and if $E = +\\infty$, $u=1$, then the walk is recurrent.\n\nWe then define $u_n$ to be the probability that a given walk is at the origin on the $n$th step, defining the value $u_0=1$ for the trivial loop. We also introduce an indicator random variable $x_n$, which takes the value $1$, if the particle is at the origin on the $n$th step and zero otherwise.\n\nThen\n\n\\begin{align*}\nT = \\sum_{n=1}^{\\infty}x_n\n\\end{align*}\n\nis the total number of times, the particle is at the origin, so $E$ is equal to the expectation of $T$, $\\mathbb{E}(T)$, which is equal to:\n\n\\begin{align*}\n\\mathbb{E}[T] &= \\sum_{n=1}^{\\infty}\\mathbb{E}[x_n]\\\\\n&= \\sum_{n=1}^{\\infty} u_n\n\\end{align*}\n\nBut, we showed previously that if $E$ is finite, then the walk is transient and if $E = \\infty$, then the walk is recurrent, so we have established that if:\n\n\\begin{align*}\n\\sum_{n=1}^{\\infty}u_n\n\\end{align*}\n\nconverges then the walk is transient and if the sum diverges, then the walk is recurrent.\n\n### $\\mathbb{Z}^1$ case\n\nNow that we have built up the necessary tools, we will consider the cases. We start by considering a simple random walk on $\\mathbb{Z}^1$. Since, as mentioned previously, a walk must have an even number of steps to be a loop, we only look at $u_{2n},n \\in \\mathbb{Z}^+$. A path of length $2n$ returning to the origin must have $n$ up-moves and $n$ down-moves. The number of such paths are ${2n \\choose n}$. Each such path has a probability of occurrence $\\frac{1}{2^{2n}}$. Thus,\n\n\\begin{align*}\nu_{2n} = \\frac{1}{2^{2n}}{2n \\choose n}\n\\end{align*}\n\nUsing Stirling's approximation $n! \\sim \\sqrt{2\\pi n} e^{-n} n^{n}$, we obtain:\n\n\\begin{align*}\nu_{2n} &= \\frac{1}{2^{2n}} \\frac{(2n)!}{n! n!}\\\\\n&\\approx \\frac{1}{2^{2n}} \\cdot \\frac{\\sqrt{2\\pi(2n)} e^{-2n}(2n)^{2n}}{\\left(\\sqrt{2\\pi n} e^{-n} n^n\\right)^2}\\\\\n&=\\frac{1}{\\sqrt{\\pi n}}\n\\end{align*}\n\nSo, we see that:\n\n\\begin{align*}\n\\sum_{n=0}^{\\infty} u_{2n} \\approx \\sum_{n=0}^{\\infty} \\frac{1}{\\sqrt{n\\pi}}\n\\end{align*}\n\nAnd the series on the right certainly diverges so, we see that a simple random walk in $\\mathbb{Z}^1$ is recurrent since $E$ diverges.\n\n### $\\mathbb{Z}^2$ case\n\nA particle has an equal probability $1/4$ of moving left, right, up or down randomly in the $d=2$ dimensional lattice. Each path of $2n$ steps has a probability $\\frac{1}{4^{2n}}$ of occurring. We then consider the number of paths with equal steps left and right (say $L$ steps in each horizontal direction) and equal steps up and down (then $n-L$) is:\n\n\\begin{align*}\n{2n \\choose L}{2n - L \\choose L}{2n - 2L \\choose n - L}{n-L \\choose n - L} = \\frac{(2n)!}{L! L! (n-L)! (n-L)!}\n\\end{align*}\n\nSo we get:\n\n\\begin{align*}\nu_{2n} &= \\frac{1}{4^{2n}} \\sum_{L=0}^n \\frac{(2n)!}{L! L! (n-L)! (n-L)!} \\\\\n&= \\frac{1}{4^{2n}} \\sum_{L=0}^n \\frac{(2n)!}{n! n!} \\cdot \\left(\\frac{n!}{L! (n-L)!}\\right)^2 \\\\\n&=\\frac{1}{4^{2n}} {2n \\choose n}\\sum_{L=0}^n {n \\choose L}^2\n\\end{align*}\n\nSuppose, we are to form a team of $n$ players from a population of $2n$ participants. There ${2n \\choose n}$ distinguishable teams of size $n$. Alternatively, we could divide the population into two halves of $n$ participants each, choose $L$ participants from the first sub-population, and the remaining $n-L$ participants from the second sub-population. So, the number of distinguishable teams is:\n\n\\begin{align*}\n\\sum_{L=0}^{n}{n \\choose L}{n \\choose n - L} = \\sum_{L=0}^{n} {n \\choose L}^2\n\\end{align*}\n\nSo, we have the combinatorial identity:\n\n\\begin{align*}\n\\sum_{L=0}^{n} {n \\choose L}^2 = {2n \\choose n}\n\\end{align*}\n\nThus,\n\n\\begin{align*}\nu_{2n} &=\\frac{1}{4^{2n}} {2n \\choose n}\\sum_{L=0}^n {n \\choose L}^2\\\\\n&= \\left(\\frac{1}{2^{2n}} {2n \\choose n}\\right)^2\n\\end{align*}\n\nSo, we have that, it is just the square of the result from $\\mathbb{Z}^1$, so we see in this case that:\n\n\\begin{align*}\nu_{2n} &\\approx \\sum_{n=0}^{\\infty} \\frac{1}{\\pi n}\n\\end{align*}\n\nAnd the series on the right certainly diverges, so we see that a simple random walk in $\\mathbb{Z}^2$ is recurrent as $E$ diverges.\n\n### $\\mathbb{Z}^3$ case\n\nAs before, in order to have a walk return to the origin we must have equal steps in the positive and negative directions for each direction and each path of $2n$ has a probability of occurring of $\\frac{1}{6^{2n}}$. Then, extending the idea from the previous subsection, the number of paths (of total length $2n$) with $L$ steps left and right, $U$ steps up and down and $n - L - U$ steps forward and backward is:\n\n\\begin{align*}\n\\frac{(2n)!}{L! L! U! U! (n - L - U)! (n - L - U)!}\n\\end{align*}\n\nSo, we get:\n\n$$\n\\begin{align*}\nu_{2n} &= \\frac{1}{6^{2n}} \\sum_{L,U,L+U \\leq n} \\frac{(2n)!}{L! L! U! U! (n - L - U)! (n - L - U)!} \\\\\n&= \\frac{1}{2^{2n}} {2n \\choose n} \\sum_{L,U,L+U \\leq n} \\left(\\frac{1}{3^n}\\frac{n!}{L! U! (n - U - L)!}\\right)^2\n\\end{align*}\n$$ {#eq-probability-of-return-to-origin-at-nth-step-in-3d}\n\nConsider a $3$-sided fair coin, with $\\mathbb{P}\\{\\text{Heads}\\} = \\mathbb{P}\\{\\text{Tails}\\} = \\mathbb{P}\\{\\text{Edge}\\} = \\frac{1}{3}$. Suppose that the coin is tossed $n=3^2 = 9$ times. The probability of landing $L$ heads, $U$ tails and $n - L - U$ edges is $\\frac{n!}{L!U!(n-L-U)!} \\frac{1}{3^n}$.  This is precisely the term seen in the above expression. The number of heads, tails and edges in $n$ coin tosses follows a multinomial distribution. It can be easily demonstrated, that in, $n/3 = 3$ heads, $n/3$ tails and $n/3$ edges are most likely to occur in $n$ coin tosses. So, we can find an upper bound on the summand in @eq-probability-of-return-to-origin-at-nth-step-in-3d as:\n\n\\begin{align*}\n\\frac{n!}{3^n L! U! (n- L - U)!} \\leq \\frac{n!}{3^n \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor!}\n\\end{align*}\n\nAlso, from the multinomial expansion theorem:\n\n\\begin{align*}\n(1 + a + b)^n = \\sum_{L,U,L+U\\leq n} \\frac{n!}{L! U! (n-L-U)!} a^L b^U\n\\end{align*}\n\nSetting $a = b = 1$, we get:\n\n\\begin{align*}\n\\sum_{L,U,L+U\\leq n} \\frac{n!}{3^n L! U! (n-L-U)!} a^L b^U = 1\n\\end{align*}\n\nWe then see that:\n\n\\begin{align*}\nu_{2n} \\leq \\frac{1}{2^{2n}} {2n \\choose n} \\frac{n!}{3^n \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor! \\lfloor\\frac{n}{3}\\rfloor!}\n\\end{align*}\n\nWe can simplify this as:\n\n\\begin{align*}\nu_{2n} &= \\frac{1}{2^{2n}}{2n \\choose n} \\frac{n!}{3^n \\left(\\lfloor\\frac{n}{3}\\rfloor!\\right)^3} \\\\\n&\\approx \\frac{1}{\\sqrt{\\pi n}} \\times \\frac{\\sqrt{2\\pi n} e^{-n} n^n}{3^n \\left\\{\\sqrt{2\\pi \\frac{n}{3}}e^{-n/3} \\left(\\frac{n}{3}\\right)^{n/3}\\right\\}^3}\\\\\n&= \\frac{1}{\\sqrt{\\pi n}} \\frac{\\sqrt{2\\pi n} e^{-n} n^n}{3^n \\frac{(2\\pi n)^{3/2}}{3^{3/2}} e^{-n} \\frac{n^n}{3^n}}\\\\\n&= \\frac{1}{\\sqrt{\\pi n}} \\frac{\\sqrt{2\\pi n} \\cancel{e^{-n}} \\cancel{n^n}}{\\cancel{3^n} \\frac{(2\\pi n)^{3/2}}{3^{3/2}} \\cancel{e^{-n}} \\frac{ \\cancel{n^n}}{\\cancel{3^n}}}\\\\\n&\\approx \\frac{M}{(\\pi n)^{3/2}}\n\\end{align*}\n\nwhere $M$ is a positive constant. We then see:\n\n\\begin{align*}\n\\sum_n u_{2n} &= M \\sum_n \\frac{1}{n^{\\frac{3}{2}}}\n\\end{align*}\n\nThe sum on the right hand side converges, so we have that a simple random walk in three dimensions is transient. The proof of Polya's Random Walk Theorem is complete.\n\n## Recurrence and Transience of Brownian Motion\n\nIn one dimension, we established that every path of a Brownian motion reaches any level $a \\in \\mathbf{R}$. More precisely, for $a > 0$, if we define the stopping time :\n\n\\begin{align*}\n\\tau = \\min \\{ t \\geq 0 : B_t \\geq a\\}\n\\end{align*}\n\nwe have $\\mathbb{P}\\{\\tau_a < \\infty \\} = 1$. This implies in particular that every path will come back to $0$ and will do infinitely many times. This is because $B(t+\\tau) - B(t)$ is a standard brownian motion. This property of Brownian motion is called *recurrence*. This is to be compared with Brownian motion with a drift. In our analysis, we found that, if the drift is negative, then there are paths that will not reach a given level $a > 0$ with positive probability. Such paths go to infinity without ever going back to $0$. This property of the process is called *transience*. \n\nWe can derive similar properties for the multidimensional Brownian motion. We will rely heavily on @cor-brownian-martingales and on some knowledge of harmonic functions. Harmonic functions play a very important role in mathematics, physics and in nature in general. As we mentioned earlier, if $d = 1$, the only harmonic functions are the linear functions, since the equation $f''(x) = 0$ has the solutions $f(x)=ax+b$. However, in higher dimensions, the collection of harmonic functions is very rich. This gives access to a plethora of Brownian martingales. For example, the following functions are harmonic in the whole space minus the origin, $\\mathbf{R}^d \\setminus \\{0\\}$.\n\n$$\nh(x) = \\begin{cases}\n\\log ||x||, & d = 2 \\\\\n||x||^{2 - d}, & d \\geq 3\n\\end{cases}\n$$ {#eq-example-of-harmonic-function}\n\nwhere $x\\in\\mathbf{R}^d$.\n\n::: {.proof}\nConsider \n\n\\begin{align*}\nf(x_1,x_2) = \\log \\sqrt {x_1^2 + x_2^2}\n\\end{align*}\n\nWe have:\n\n\\begin{align*}\n\\frac{\\partial f}{\\partial x_1} &= \\frac{1}{\\sqrt{x_1^2 + x_2^2}} \\cdot \\frac{\\partial }{\\partial x_1} (\\sqrt{x_1^2 + x_2^2})\\\\\n&=\\frac{1}{\\sqrt{x_1^2 + x_2^2}} \\cdot \\frac{x_1}{\\sqrt{x_1^2 + x_2^2}}\\\\\n&= \\frac{x_1}{x_1^2 + x_2^2}\n\\end{align*}\n\nFurther,\n\n\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x_1^2} &= \\frac{(x_1^2 + x_2^2)(1) - x_1(2x_1)}{(x_1^2 + x_2^2)^2} \\\\\n&= \\frac{x_1^2 - x_2^2}{(x_1^2 + x_2^2)}\n\\end{align*}\n\nBy symmetry,\n\n\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x_2^2} \n&= \\frac{x_2^2 - x_1^2}{(x_1^2 + x_2^2)}\n\\end{align*}\n\nSo, \n\n\\begin{align*}\n\\frac{\\partial^2 f}{\\partial x_1^2} &= - \\frac{\\partial^2 f}{\\partial x_2^2}\\\\\n\\frac{\\partial^2 f}{\\partial x_1^2} + \\frac{\\partial^2 f}{\\partial x_2^2}&=0\n\\end{align*}\n\nWe conclude that $f$ is harmonic.\n\nNext, consider \n\n\\begin{align*}\ng(x_1,x_2,\\ldots,x_d) = \\frac{1}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-2}}\n\\end{align*}\n\nNow,\n\n\\begin{align*}\n\\frac{\\partial g}{\\partial x_i} &= \\frac{(2-d)}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-1}} \\cdot \\frac{\\partial }{\\partial x_i}\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)\\\\\n &= \\frac{(2-d)}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-1}}\\cdot \\frac{2x_i}{2\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)}\\\\\n &= \\frac{(2-d)x_i}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^d}\n\\end{align*}\n\nFurther, we have:\n\n\\begin{align*}\n\\frac{\\partial^2 g}{\\partial x_i^2} &= (2-d)\\frac{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^d (1) - (x_i)\\cdot d \\cdot\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-1}\\cdot \\frac{x_i}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)}}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{2d}}\\\\\n&=(2-d)\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{d-2} \\frac{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^2  - d x_i^2}{\\left(\\sqrt{x_1^2 + x_2^2 + \\ldots + x_d^2}\\right)^{2d}}\\\\\n&=(2-d) \\frac{\\left(\\sum_{i=1}^d x_i^2\\right) - dx_i^2 }{||x||^{d+2}}\n\\end{align*}\n\nWe conclude that:\n\n\\begin{align*}\n\\sum_{i=1}^{d} \\frac{\\partial^2 g}{\\partial x_i^2} = 0\n\\end{align*}\n\nand hence $g$ is harmonic.\n:::\n\nInterestingly enough, the answer to the recurrence versus transience puzzle depends on the dimension. We will show that Brownian motion is recurrent in dimension $d=2$ in the sense that every Brownian motion path starting from $x$ will eventually enter a disc around the origin, no matter how small the disc is. The Brownian path will then enter this disc infinitely many times, as $t \\to \\infty$. Note that, we did not say that the path actually hits $0$, but that *it enters a disc around the $0$*. This nuance is important, as we will in fact show that a Brownian path actually never hits a given point. In dimension $d=3$ or higher, it is proved that there are some paths starting from a given $x$ that will never enter a given ball around the origin with positive probability. This is the transience property. \n\nThe strategy of the proof is similar to the approach for Brownian motion with a drift. We will find a good function $h : \\mathbf{R}^d \\to \\mathbf{R}$ for which $h(B_t)$ is a martingale. In light of @cor-brownian-martingales, this function needs to be harmonic in a suitable region. The desired probability is then obtained by considering the right boundary values.\n\n::: {#thm-recurrence-and-transience-of-brownian-motion}\n### Recurrence and transience of a brownian motion in $\\mathbf{R}^d$\n\nLet $(B_t,t\\geq 0)$ be a Brownian motion in $\\mathbf{R}^d$ starting at $B_0 = x$. Consider for $r < ||x||$, the stopping time \n\n\\begin{align*}\n\\tau_r = \\min \\{t \\geq 0 : ||B_t|| < r\\}\n\\end{align*}\n\nthe first hitting time of the paths in a ball of radius $r$ around the origin. We have:\n\n\\begin{align*}\n\\mathbb{P}(\\tau_r < \\infty) = \n\\begin{cases}\n1 & \\text{ if }d \\leq 2 \\\\\n\\left(\\frac{r}{||x||}\\right)^{d-2} & \\text{ if }d \\geq 3\n\\end{cases}\n\\end{align*}\n\nIn particular, for $d \\leq 2$, the paths are recurrent; that is, they come back infinitely many times in a neighbourhood of the origin. For $d \\geq 3$, each path will eventually never come back to a neighbourhood of the origin.\n:::\n\nNote that we made sure that the starting point of the Brownian motion $x$ is outside the ball of radius $r$.\n\n::: {.proof}\nConsider another hitting time of a ball with a radius larger than $||x||$:\n\n\\begin{align*}\n\\tau_R' = \\min \\{t \\geq 0 : ||B_t|| \\geq R\\}, \\quad r < ||x|| < R\n\\end{align*}\n\nNote that $\\tau_R'$ must increase with $R$ and that it must go to $+\\infty$ as $R \\to \\infty$. Moreover, the sequence of events $\\{\\tau_r < \\tau_R'\\}_{R > ||x||}$ is increasing. In particular, by continuity of probability measure, we have:\n\n\\begin{align*}\n\\lim_{R \\to \\infty} \\mathbb{P}(\\tau_r < \\tau_R') &= \\mathbb{P}(\\lim_{R \\to \\infty} \\tau_r < \\tau_R')\\\\\n&= \\mathbb{P}(\\tau_r < \\infty)\n\\end{align*}\n\nIf we set $\\tau = \\tau_r \\land \\tau_R'$, then the event $\\{\\tau_r < \\tau_R'\\}$ is the same as the event $\\{||B_\\tau||=r\\}$. So, $\\lim_{R \\to \\infty} \\mathbb{P}(\\tau_r < \\tau_R') = \\lim_{R \\to \\infty} \\mathbb{P}(||B_\\tau||=r)$.\n\nNow, consider the event $\\{\\tau < \\infty\\}$. Let $E_n$ be the event that the $n$th increment $||B_n - B_{n-1}||$ exceeds $R$. If $E_n$ occurs, then we must have the Brownian motion exits the spherical shell of thickness $R-r$. Moreover, we have $\\mathbb{P}(E_1) = \\ldots = \\mathbb{P}(E_n)$, for all $n$. Call this probability $p$. Clearly, $0 < p < 1$. Since the events $E_n$ are independent, we have:\n\n\\begin{align*}\n\\mathbb{P}(E_1^C \\cap \\ldots \\cap E_n^C) = (1 - p)^n\n\\end{align*}\n\nAs $n \\to \\infty$, we have $\\lim_{n \\to \\infty} \\mathbb{P}(\\bigcap_{k=1}^{n}E_k^C) = 0$. Now, let $F_k$ be the event that there are no excursions upto $k$. That is, $F_k = \\bigcap_{i=1}^{k}E_i^C$. Now, the event $F_{k+1}$ implies $F_k$, or equivalently, $F_{k+1} \\subseteq F_k$. So, $\\{F_k\\}_{k=1}^{\\infty}$ is a decreasing sequence of events. Moreover, $\\bigcap_{k=1}^n F_k = \\bigcap_{k=1}^n E_k^C$. So, by continuity of probability measure,\n\n\\begin{align*}\n\\lim_{n \\to \\infty} \\mathbb{P}(\\bigcap_{k=1}^{n}E_k^C) \n&= \\lim_{n \\to \\infty} \\mathbb{P}(\\bigcap_{k=1}^{n}F_k) \\\\\n&= \\mathbb{P}(\\lim_{n \\to \\infty} \\bigcap_{k=1}^{n}F_k) \\\\\n&= \\mathbb{P}(\\bigcap_{k=1}^{\\infty}F_k) \\\\\n&= \\mathbb{P}(\\bigcap_{k=1}^{\\infty}E_k^C) \n\\end{align*}\n\nSo, $\\mathbb{P}(\\bigcup_{k=1}^{\\infty}E_k) = 1$. There exists an $n_0 \\in \\mathbf{N}$, such that the event $E_{n_0}$, an excursion at $n_0$ occurs with probability $1$. So, the event $\\{\\tau < \\infty\\}$ occurs almost surely.\n\nTo compute $\\mathbb{P}(||B_\\tau||=r)$, the idea is to find a good function $h$ with the following properties:\n\n- **Martingale**: $(h(B_t),t\\leq \\tau)$ is a bounded martingale, so that the optional stopping theorem implies:\n\n\\begin{align*}\n\\mathbb{E}[h(B_\\tau)] = h(B_0) = h(x)\n\\end{align*}\n\n- **Boundary values**: Since $B_\\tau$ is a point at $||x||=r$ or at $||x||=R$, we pick boundary conditions for $h$, so that $\\mathbb{E}[h(B_{\\tau})]=\\mathbb{P}(||B_\\tau||=r)$. \n\nThe second point is easy; it suffices to take the *boundary conditions* $h(x)=0$ at $||x||=R$ and $h(x)=1$ at $||x||=r$. For the first point, by Ito's formula, we pick $h$ to be harmonic in the annulus $\\{x \\in \\mathbf{R}^d : r < ||x||<R \\}$. Thus, we can use the function in @eq-example-of-harmonic-function. Of course, the functions $ah(x) + b$ remain harmonic. To satisfy the boundary conditions, we pick $a$ and $b$ suitably:\n\n\n### $\\mathbb{R}^1$ case\n\nLet $h(x) = ax + b$. Then, at $x=r$, we have:\n\n$$\n\\begin{align*}\nar + b = 1\n\\end{align*}\n$$ {#eq-boundary-condition-5}\n\nand at $x = R$, we have:\n\n$$\n\\begin{align*}\naR + b = 0\n\\end{align*}\n$$ {#eq-boundary-condition-6}\n\nSo, $b = -aR$. Substituting in @eq-boundary-condition-5, we get:\n\n\\begin{align*}\na &= \\frac{1}{r - R}\nb &= -\\frac{R}{r - R}\n\\end{align*}\n\nConsequently,\n\n$$\n\\begin{align*}\nh(x) &= \\frac{R - x}{R - r}\n\\end{align*}\n$$  {#eq-h(x)-R1-case}\n\n### $\\mathbb{R}^2$ case\n\nLet $h(x) = \\log ||x||$. Then, at $||x||=r$, we have:\n\n$$\n\\begin{align*}\na \\log ||x|| + b &= 1\na \\log r + b &= 1\n\\end{align*}\n$$ {#eq-boundary-condition-1}\n\nAt $||x||=R$, we have:\n\n$$\n\\begin{align*}\na \\log ||x|| + b &= 0\na \\log R + b &= 0\n\\end{align*}\n$$ {#eq-boundary-condition-2}\n\nThus, from @eq-boundary-condition-2, $b = -a \\log R$. Substituting the value for $b$ in @eq-boundary-condition-1, we have:\n\n$$\n\\begin{align*}\na \\log r - a \\log R &= 1\\\\\na &= \\frac{1}{\\log r - \\log R}\n\\end{align*}\n$$\n\nConsequently, \n\n$$\n\\begin{align*}\nh(x) &= \\frac{\\log ||x||}{\\log r - \\log R} -  \\frac{1}{\\log r - \\log R} \\log R\\\\\n&= \\frac{\\log R - \\log ||x||}{\\log R - \\log r}\n\\end{align*}\n$$ {#eq-h(x)-R2-case}\n\n### $\\mathbb{R}^d$, $d \\geq 3$ case\n\nLet $h(x)=||x||^{2-d}$. At $||x||=r$, $a h(x) + b = 1$. So, we have:\n\n$$\n\\begin{align*}\na r^{2-d} + b = 1\n\\end{align*}\n$$ {#eq-boundary-condition-3}\n\nAt $||x||=R$, $ah(x) + b = 0$. So, we have:\n\n$$\n\\begin{align*}\na ||R||^{2-d} + b &= 0\n\\end{align*}\n$$  {#eq-boundary-condition-4}\n\nFrom @eq-boundary-condition-4, we get $b = -a R^{2-d}$. Substituting this value in @eq-boundary-condition-3, we get:\n\n\\begin{align*}\na r^{2-d} - aR^{2-d}  &= 1\\\\\na &= \\frac{1}{r^{2-d} - R^{2-d}}\n\\end{align*}\n\nAnd \n\n$$\n\\begin{align*}\nb = - \\frac{R^{2-d}}{r^{2-d} - R^{2-d}}\n\\end{align*}\n$$\n\nThus,\n\n$$\n\\begin{align*}\nh(x) &= \\frac{||x||^{2-d}}{r^{2-d} - R^{2-d}} - \\frac{R^{2-d}}{r^{2-d} - R^{2-d}}\\\\\n&= \\frac{R^{2-d} - ||x||}{R^{2-d} - r^{2-d}}\n\\end{align*}\n$$  {#eq-h(x)-R3-case}\n\nCollecting all the results together, we get:\n\n$$\nh(x) = \\begin{cases}\n\\frac{R - x}{R - r}, & d=1 \\\\\n\\frac{\\log R - \\log ||x||}{\\log R - \\log r}, & d=2 \\\\\n\\frac{R^{2-d} - ||x||^{2-d}}{R^{2-d} - r^{2-d}}, & d \\geq 3\n\\end{cases}\n$$ {#eq-hx-in-Rd-case}\n\nPassing to the limit as $R \\to \\infty$, for $d=1$, we have:\n\n\\begin{align*}\n\\lim_{R \\to \\infty} h(x) &= \\lim_{R \\to \\infty} \\frac{R - x}{R - r} \\\\\n&= \\lim_{R \\to \\infty} \\frac{1 - \\frac{x}{R}}{1 - \\frac{r}{R}}\\\\\n&= 1\n\\end{align*}\n\nFor $d = 2$, we get:\n\n\\begin{align*}\n\\lim_{R \\to \\infty} h(x) &= \\lim_{R \\to \\infty} \\frac{1 - \\frac{\\log x}{\\log R}}{1 - \\frac{\\log r}{\\log R}} \\\\\n&= 1\n\\end{align*}\n\nFor $d = 3$, we get:\n\n\\begin{align*}\n\\lim_{R \\to \\infty}  h(x) &= \\lim_{R \\to \\infty} \\frac{R^{2-d} - ||x||^{2-d}}{R^{2-d} - r^{2-d}}\\\\\n&= \\left(\\frac{||x||}{r}\\right)^{2-d}\n\\end{align*}\n\nThis concludes the proof. $\\blacksquare$\n:::\n\n::: {#exm-brownian-path-in-Rd-never-hits-a-given-point}\n\nWe get more from the above proof. Indeed, in dimension $d \\geq 2$, it implies that the probability that a Brownian motion starting at $B_0 = x$ eventually hits any other point $y$ is $0$. Indeed, if we take $y = 0$ and $x \\neq 0$, we have:\n\n$$\n\\begin{align*}\n\\mathbb{P}(\\exists t > 0: B_t = 0) &= \\lim_{R \\to \\infty} \\lim_{r \\to \\infty} \\mathbb{P}(\\tau_r < \\tau_R')\\\\\n&= \\lim_{R \\to \\infty} \\lim_{r \\to \\infty} \\frac{R^{2-d} - ||x||^{2-d}}{R^{2-d} - r^{2-d}}\\\\\n&=\\lim_{R \\to \\infty}  \\lim_{r \\to \\infty} \\frac{(R/r)^{2-d} - (||x||/r)^{2-d}}{(R/r)^{2-d} - 1}\\\\\n&= \\lim_{R \\to \\infty} 0\\\\\n&= 0\n\\end{align*}\n$$\n\nHere, we shrink the inner radius to $0$ first and then we let the outer radius go to infinity after. It remains to take the limits of the expression obtained in equation @eq-hx-in-Rd-case. The first limit $r \\to 0$ gives $0$ right away.\n:::\n\n## Dynkin's Formula and the Dirichlet Problem\n\nIn the last section, we translated the problem of recurrence and transience of Brownian motion in terms of a *boundary value problem*: we needed to find a particular function $h$ that solves a PDE (that is, $\\nabla^2 h=0$) in a certain region of space(the annulus) and that satisfies given boundary conditions (the function is $1$ on the inner circle and $0$ on the outer circle). This is a particular case of the *Dirichlet problem* in PDE.\n\nConsider a region $\\mathcal{O} \\subset \\mathbb{R}^d$. $\\mathcal{O}$ is an open ball. That is, for all $x \\in \\mathcal{O}$, there exists $\\epsilon>0$, such that $V_\\epsilon(x) = \\{y : ||y - x|| < \\epsilon\\}$ is contained in $\\mathcal{O}$. $\\mathcal{O}$ doesn't contain boundary points $\\partial \\mathcal{O}$. In the proof of @thm-recurrence-and-transience-of-brownian-motion, the region was the annulus $\\{x: r < ||x|| < R\\}$ and the boundary was given by the spheres $\\{x :||x|| = r\\}$ and $\\{x: ||x||=R\\}$. The Dirichlet problem in $\\mathcal{O}$ can be stated as follows:\n\nLet $f:\\partial\\mathcal{O} \\to \\mathbb{R}$ be a function on the boundary of $\\mathcal{O}$. Can we extend the function $f$ to $O$ in such a way that the extension is harmonic on $\\mathcal{O}$ and coincides with $f$ on the boundary?\n\nIn the instance of the proof of the @thm-recurrence-and-transience-of-brownian-motion, we knew the solution of the problem, thanks to @eq-example-of-harmonic-function. The only job left to do was to adjust some parameters to fit the boundary conditions. It turns out that the formalism of stochastic calculus allows us to express the solution of the Dirichlet problem as an average over Brownian paths for general regions of space and boundary conditions. To do so, we look at a twist on the Ito's formula called the *Dynkin's formula*.\n\nLet $x$ be a point in $\\mathcal{O}$. Consider a Brownian motion $(B_t,t\\geq 0)$ starting at $x$, $B_0 = x$. To emphasize the dependence on $x$, we write $\\mathbb{P}_x$ and $\\mathbb{E}_x$ for the probability and the expectation for the Brownian motion. Dykin's formula is obtained by merging @cor-brownian-martingales for the Brownian martingales together with the optional stopping theorem. More precisely, consider $f \\in C^2(\\mathbb{R}^d)$ that satisfies the assumption of the @cor-brownian-martingales. We then have that the process:\n\n\\begin{align*}\nM_t &= f(B_t) - \\frac{1}{2}\\int_{0}^t \\nabla^2 f(B_s) ds, \\quad t \\geq 0\n\\end{align*}\n\nis a Brownian martingale. \n\nConsider also the stopping time $\\tau = \\min \\{t \\geq 0 : B_t \\in \\mathcal{O}^C\\}$. This is the first exit time of $\\mathcal{O}$ of the Brownian motion path. Then, if the assumptions of the optional stopping theorem are fulfilled, we get *Dynkin's formula*:\n\n$$\n\\begin{align*}\n\\mathbb{E}[M_\\tau] = \\mathbb{E}[f(B_\\tau)] - \\frac{1}{2} \\mathbb{E}\\left[\\int_0^\\tau \\nabla^2 f(B_s)ds\\right] = f(B_0) = M_0\n\\end{align*}\n$$ {#eq-dynkins-formula}\n\nAs an application of Dynkin's formula, let's express the solution of the Dirichlet problem as an average over Brownian motion. If $f$ is harmonic in $\\mathcal{O}$, then $\\nabla^2 f = 0$ in $\\mathcal{O}$, so the process $(f(B_t),t\\leq \\tau)$ is itself a martingale. Note that since $\\mathcal{O}$ is bounded, this is a bounded martingale! Moreover, the integrands $\\partial_i f(B_s)$, $1 \\leq i \\leq d$, are bounded. We conclude that the solution to the Dirichlet problem can be represented as follows:\n\n$$\n\\begin{align*}\nf(x) = \\mathbb{E}_x[f(B_\\tau)], \\quad x \\in \\mathcal{O}\n\\end{align*}\n$$ {#eq-dynkins-formula-applied-to-dirichlet-problem}\n\nIn other words, the value of the harmonic function of $f$ at $x$ is given by the average over the Brownian paths of the value of the function at the exit point of the path on the boundary of $\\mathcal{O}$. Equation @eq-dynkins-formula-applied-to-dirichlet-problem does not prove the existence of the solution to the Dirichlet problem, as we assume that such a function exists. Existence of the solution to the Dirichlet problem can be shown this way, assuming the region $\\mathcal{O}$ and the function on the boundary are nice enough. However, note that the averaging on the right-hand side of the formula makes sense even in the case where $f$ is simply defined on the boundary $\\partial \\mathcal{O}$. We then define a posteriori the *harmonic extension* of $f$ inside $\\mathcal{O}$ by defining its value at $x$ as $\\mathbb{E}_x[f(B_\\tau)]$. \n\n## Numerical Projects\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}