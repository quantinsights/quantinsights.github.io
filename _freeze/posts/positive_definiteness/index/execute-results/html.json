{
  "hash": "6a2d42aaf284ce40b55dd26bec07b751",
  "result": {
    "markdown": "---\ntitle: \"Positive Definiteness\"\nauthor: \"Quasar\"\ndate: \"2024-06-20\"\ncategories: [Linear Algebra]      \nimage: \"image.jpg\"\ntoc: true\ntoc-depth: 3\n---\n\n## Positive Definite Matrices\n\n*Definition 1*. A real-valued matrix $A$ is *positive-definite* (written as $A \\succ 0$), if for every real valued vector $\\mathbf{x}$, the quadratic form\n\n\\begin{align*}\nq(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x} > 0\n\\end{align*}\n\nThe matrix $A$ is positive semi-definite (written as $A \\succeq 0$) if :\n\n\\begin{align*}\nq(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x} \\geq 0\n\\end{align*}\n\n$\\forall \\mathbf{x} \\in \\mathbf{R}^n$.\n\nIntuitively, positive definite matrices are like strictly positive real numbers. Consider a scalar $a > 0$. The sign of $ax$ will depend on the sign of $x$. And $x\\cdot ax > 0$. However, if $a < 0$, multiplying it with $x$ will flip the sign, so $x$ and $ax$ have opposite signs and $x \\cdot ax < 0$. \n\nIf $A \\succ 0$, then by definition $\\mathbf{x}^T A \\mathbf{x} > 0$ for all $\\mathbf{x} \\in \\mathbf{R}^n$. Thus, the vector $\\mathbf{x}$ and it's transformed self $A\\mathbf{x}$ should make an angle $\\theta \\in \\left[-\\frac{\\pi}{2},\\frac{\\pi}{2}\\right]$. Both $\\mathbf{x}$ and $A\\mathbf{x}$ lie on the same side of the hyperplane $\\mathbf{x}^{\\perp}$.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n%load_ext itikz\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\n%%itikz --temp-dir --tex-packages=tikz --tikz-libraries=arrows --implicit-standalone\n\\begin{tikzpicture}[scale=1.5]\n\\draw [->] (-2,0) -- (6,0) node [below] {\\huge $x_1$};\n\\draw [->] (0,-2) -- (0,6) node [above] {\\huge $x_2$};\n\\draw [->] (0,0) -- (3,1) node [above] {\\huge $\\mathbf{x}$};\n\\draw [->] (0,0) -- (2,5) node [above] {\\huge $A\\mathbf{x}$};\n\\draw [dashed] (-2,6) -- (1,-3) node [] {\\huge $\\mathbf{x}^{\\perp}$};\n\\draw[draw=green!50!black,thick] (1,1/3) arc (18.43:68.19:1) node [midway,above] {\\huge $\\theta$};\n\\end{tikzpicture}\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n![](index_files/figure-html/cell-3-output-1.svg){}\n:::\n:::\n\n\n## Convex functions\n\nThere is a second geometric way to think about positive definite matrices : a quadratic form is convex when the matrix is symmetric and positive definite.\n\n*Definition 2.* (Convex function) A function $f:\\mathbf{R}^n \\to \\mathbf{R}$ is *convex*, if for all $\\mathbf{x},\\mathbf{y}\\in \\mathbf{R}^n$ and $0 \\leq \\lambda \\leq 1$, we have:\n\n\\begin{align*}\nf(\\lambda \\mathbf{x} + (1-\\lambda)\\mathbf{y}) \\leq \\lambda f(\\mathbf{x}) + (1-\\lambda) f(\\mathbf{y}) \\tag{1}\n\\end{align*}\n\n*Proposition 3.* Assume that the function $f:\\mathbf{R}^n \\to \\mathbf{R}$ is differentiable. Then, $f$ is convex, if and only if, for all $\\mathbf{x},\\mathbf{y} \\in \\mathbf{R}^n$, the inequality\n\n\\begin{align*}\nf(\\mathbf{y}) \\geq f(\\mathbf{x}) + \\nabla f(\\mathbf{y})^T (\\mathbf{y} - \\mathbf{x}) \\tag{2}\n\\end{align*}\n\nis satisfied.\n\n*Proof.*\n\n$\\Longrightarrow$ direction.\n\nAssume that $f$ is convex and let $\\mathbf{x} \\neq \\mathbf{y} \\in \\mathbf{R}^n$. The convexity of $f$ implies that:\n\n\\begin{align*}\nf((\\mathbf{x} + \\mathbf{y})/2) \\leq \\frac{1}{2}f(\\mathbf{x}) + \\frac{1}{2}f(\\mathbf{y}) \n\\end{align*}\n\nDenote now $\\mathbf{h} = \\mathbf{y}-\\mathbf{x}$. Then this inequality reads:\n\n\\begin{align*}\nf(\\mathbf{x} + \\mathbf{h}/2) \\leq \\frac{1}{2} f(\\mathbf{x}) + \\frac{1}{2}f(\\mathbf{x} + \\mathbf{h}) \n\\end{align*}\n\nUsing elementary transformations, we have:\n\n\\begin{align*}\n\\frac{f(\\mathbf{x} + \\mathbf{h}/2)}{1/2} &\\leq f(\\mathbf{x}) + f(\\mathbf{x} + \\mathbf{h}) \\\\\nf(\\mathbf{x} + \\mathbf{h}) - f(\\mathbf{x}) &\\geq \\frac{f(\\mathbf{x} + \\mathbf{h}/2) - f(\\mathbf{x})}{1/2} \n\\end{align*}\n\nRepeating this line of argumentation:\n\n\\begin{align*}\nf(\\mathbf{x} + \\mathbf{h}) - f(\\mathbf{x}) \\geq \\frac{f(\\mathbf{x} + \\mathbf{h}/2) - f(\\mathbf{x})}{1/2} \\geq \\frac{f(\\mathbf{x} + \\mathbf{h}/4) - f(\\mathbf{x})}{1/4}\n\\end{align*}\n\nConsequently,\n\n\\begin{align*}\nf(\\mathbf{x} + \\mathbf{h}) - f(\\mathbf{x}) \\geq \\frac{f(\\mathbf{x} + 2^{-k}\\mathbf{h}) - f(\\mathbf{x})}{2^{-k}} \\tag{2}\n\\end{align*}\n\nBy the order limit theorem,\n\n\\begin{align*}\nf(\\mathbf{x} + \\mathbf{h}) - f(\\mathbf{x}) \\geq \\lim_{k \\to \\infty}\\frac{f(\\mathbf{x} + 2^{-k}\\mathbf{h}) - f(\\mathbf{x})}{2^{-k}} = D_{\\mathbf{h}}f(\\mathbf{x}) = \\nabla f(\\mathbf{x}) \\cdot (\\mathbf{y} - \\mathbf{x}) \n\\end{align*}\n\nReplacing $\\mathbf{y}-\\mathbf{x}$ by $\\mathbf{h}$, we have:\n\n\\begin{align*}\nf(\\mathbf{y}) \\geq f(\\mathbf{x}) + \\nabla f(\\mathbf{x})^T (\\mathbf{y} - \\mathbf{x})\n\\end{align*}\n\n$\\Longleftarrow$ direction.\n\nLet $\\mathbf{w}, \\mathbf{z} \\in \\mathbf{R}^n$. Moreover, denote:\n\n\\begin{align*}\n\\mathbf{x} := \\lambda \\mathbf{w} + (1-\\lambda)\\mathbf{z}\n\\end{align*}\n\nThen, the inequality in (1) implies that:\n\n\\begin{align*}\nf(\\mathbf{w}) &\\geq f(\\mathbf{x}) + \\nabla f(\\mathbf{x})^T (\\mathbf{w} - \\mathbf{x})\\\\\nf(\\mathbf{z}) &\\geq f(\\mathbf{x}) + \\nabla f(\\mathbf{x})^T (\\mathbf{z} - \\mathbf{x}) \\tag{3}\n\\end{align*}\n\nNote moreover that:\n\n\\begin{align*}\n\\mathbf{w} - \\mathbf{x} &= (1-\\lambda)(\\mathbf{w}-\\mathbf{z})\\\\\n\\mathbf{z} - \\mathbf{x} &= \\lambda(\\mathbf{z}-\\mathbf{w})\n\\end{align*}\n\nThus, if we multiply the first line in (3) with $\\lambda$ and the second line with $(1-\\lambda)$ and then add the two inequalities, we obtain:\n\n\\begin{align*}\n\\lambda f(\\mathbf{w}) + (1-\\lambda)f(\\mathbf{z}) &\\geq f(\\mathbf{x}) + \\nabla f(\\mathbf{x})[\\lambda(1-\\lambda)(\\mathbf{w} - \\mathbf{z} + \\mathbf{z} - \\mathbf{w})\\\\\n&=f(\\lambda \\mathbf{w} + (1-\\lambda)\\mathbf{z})\n\\end{align*}\n\nSince $\\mathbf{w}$ and $\\mathbf{z}$ were arbitrary, this proves the convexity of $f$. \n\nThe convexity of a differentiable function can either be characterized by the fact that all secants lie above the graph or that all tangents lie below the graph.\n\nWe state the next corollary without proof.\n\n*Corollary 4*. Assume that $f:\\mathbf{R}^n \\to \\mathbf{R}$ is convex and differentiable. Then $\\mathbf{x}^*$ is a global minimizer of $f$, if and only if $\\nabla f(\\mathbf{x}^{*}) = 0$.\n\n### Hessians of convex functions.\n\n*Proposition 5.* (Second derivative test) Let $f:X\\subseteq\\mathbf{R}^n \\to \\mathbf{R}$ be a $C^2$ function and suppose that $\\mathbf{a}\\in X$ is a critical point of $f$. If the hessian $\\nabla^2 f(\\mathbf{a})$ is positive definite, then $f$ has a local minimum at $\\mathbf{a}$.\n\n*Proof.*\n\nLet $q(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x}$ be a quadratic form. We have:\n\n\\begin{align*}\nq(\\lambda \\mathbf{h}) &= (\\lambda \\mathbf{x}^T) A (\\lambda \\mathbf{x})\\\\\n&= \\lambda^2 \\mathbf{x}^T A \\mathbf{x}\\\\\n&= \\lambda^2 q(\\mathbf{x}) \\tag{4}\n\\end{align*}\n\nWe show that if $A$ is the symmetric matrix associated with a positive definite quadratic form $q(\\mathbf{x})$, then there exists $M > 0$ such that:\n\n\\begin{align*}\nq(\\mathbf{h}) \\geq M ||\\mathbf{h}||^2 \\tag{5}\n\\end{align*}\n\nfor all $\\mathbf{h} \\in \\mathbf{R}^n$.\n\nFirst note that when $\\mathbf{h} = \\mathbf{0}$, then $q(\\mathbf{h})=q(\\mathbf{0})=0$, so the conclusion holds trivially in this case.\n\nNext, suppose that when $\\mathbf{h}$ is a unit vector, that is $||\\mathbf{h}||=1$. The set of all unit vectors in $\\mathbf{R}^n$ is an $(n-1)$-dimensional hypersphere, which is a compact set. By the extreme-value theorem, the restriction of $q$ to $S$ must achieve a global minimum value $M$ somewhere on $S$. Thus, $q(\\mathbf{h}) \\geq M$ for all $\\mathbf{h} \\in S$. \n\nFinally, let $\\mathbf{h}$ be any nonzero vector in $\\mathbf{R}^n$. Then, its normalization $\\mathbf{h}/||\\mathbf{h}||$ is a unit vector and also lies in $S$. Therefore, by the result of step 1, we have:\n\n\\begin{align*}\nq(\\mathbf{h}) &= q\\left(||\\mathbf{h}|| \\cdot \\frac{\\mathbf{h}}{||\\mathbf{h}||} \\right)\\\\\n&= ||\\mathbf{h}||^2 q\\left(\\frac{\\mathbf{h}}{||\\mathbf{h}||}\\right)\\\\\n&\\geq M ||\\mathbf{h}||^2\n\\end{align*}\n\nWe can now prove the theorem. \n\nBy the second order Taylor's formula, we have that, for the critical point $\\mathbf{a}$ of $f$,\n\n\\begin{align*}\nf(\\mathbf{x}) = f(\\mathbf{a}) + \\nabla f(\\mathbf{x})\\cdot(\\mathbf{x} - \\mathbf{a}) + \\frac{1}{2}(\\mathbf{x} - \\mathbf{a})^T \\nabla^2 f(\\mathbf{a}) (\\mathbf{x} - \\mathbf{a}) + R_2(\\mathbf{x},\\mathbf{a}) \\tag{6}\n\\end{align*}\n\nwhere $R_2(\\mathbf{x},\\mathbf{a})/||\\mathbf{x}-\\mathbf{a}||^2 \\to 0$ as $\\mathbf{x} \\to \\mathbf{a}$.\n\nIf $\\nabla^2 f(\\mathbf{a}) \\succ 0$, then \n\n\\begin{align*}\n\\frac{1}{2}(\\mathbf{x} - \\mathbf{a})^T \\nabla^2 f(\\mathbf{a}) (\\mathbf{x} - \\mathbf{a}) \\geq M||\\mathbf{x} - \\mathbf{a}||^2 \\tag{7}\n\\end{align*}\n\nPick $\\epsilon  = M$. By the definition of limits, since $R_2(\\mathbf{x},\\mathbf{a})/||\\mathbf{x} - \\mathbf{a}||^2 \\to 0$ as $\\mathbf{x} \\to \\mathbf{a}$, there exists $\\delta > 0$, such that for all $||\\mathbf{x} - \\mathbf{a}||<\\delta$, $|R_2(\\mathbf{x},\\mathbf{a})|/||\\mathbf{x} - \\mathbf{a}||^2 < M$. Or equivalently,\n\n\\begin{align*}\n|R_2(\\mathbf{x},\\mathbf{a})| < M||\\mathbf{x}-\\mathbf{a}||^2 \n\\end{align*}\n\nthat is:\n\n\\begin{align*}\n-M||\\mathbf{x}-\\mathbf{a}||^2 < R_2(\\mathbf{x},\\mathbf{a}) < M||\\mathbf{x}-\\mathbf{a}||^2 \\tag{8}\n\\end{align*}\n\nPutting together (6), (7) and (8),\n\n\\begin{align*}\nf(\\mathbf{x}) - f(\\mathbf{a}) > 0\n\\end{align*}\n\nso that $f$ has a minimum at $\\mathbf{a}$.\n\n*Proposition 6*. A twice differentiable function $f:\\mathbf{R}^n \\to \\mathbf{R}$ is convex, if and only if, the hessian $\\nabla^2 f(\\mathbf{x})$ is positive semi-definite for all $\\mathbf{x}\\in\\mathbf{R}^n$.\n\n*Proof.*\n\nAssume first that $f$ is convex and let $\\mathbf{x}\\in\\mathbf{R}^n$. Define the $g:\\mathbf{R}^n \\to \\mathbf{R}$ as a function of the vector $\\mathbf{y}$ setting:\n\n\\begin{align*}\ng(\\mathbf{y}) := f(\\mathbf{y}) - \\nabla f(\\mathbf{x})^T (\\mathbf{y} - \\mathbf{x})\n\\end{align*}\n\nConsider the mapping $T(\\mathbf{y}) = -\\nabla f(\\mathbf{x})^T (\\mathbf{y} - \\mathbf{x})$. We have:\n\n\\begin{align*}\nT(\\lambda \\mathbf{y}_1 + (1-\\lambda)\\mathbf{y}_2) &= -\\nabla f(\\mathbf{x})^T (\\lambda \\mathbf{y}_1 + (1-\\lambda)\\mathbf{y}_2 - \\mathbf{x}) \\\\\n&= \\lambda [-\\nabla f(\\mathbf{x})^T (\\mathbf{y}_1 - \\mathbf{x})] + (1-\\lambda)[-\\nabla f(\\mathbf{x})^T (\\mathbf{y}_2 - \\mathbf{x})]\\\\\n&=\\lambda T(\\mathbf{y}_1) + (1-\\lambda)T(\\mathbf{y}_2)\n\\end{align*}\n\nThus, $T$ is an affine transformation. \n\nSince an affine transformation is convex and $f$ is convex, their sum $g$ is also convex. Moreover $g$ is a function of $\\mathbf{y}$, treating $\\mathbf{x}$ as a constant, we have:\n\n\\begin{align*}\n\\nabla g(\\mathbf{y}) = \\nabla f(\\mathbf{y}) - \\nabla f(\\mathbf{x})\n\\end{align*}\n\nand \n\n\\begin{align*}\n\\nabla^2 g(\\mathbf{y}) = \\nabla^2 f(\\mathbf{y})\n\\end{align*}\n\nfor all $\\mathbf{y} \\in \\mathbf{R}^n$. In particular, $\\nabla g(\\mathbf{x}) = 0$. Thus, corollary (4) implies that $\\mathbf{x}$ is a global minimizer of $g$. Now, the second order necessary condition for a minimizer implies that $\\nabla^2 g(\\mathbf{x})$ is positive semi-definite. Since $\\nabla^2 g(\\mathbf{x}) = \\nabla^2 f(\\mathbf{x})$, this proves that the Hessian of $f$ is positive semi-definite for all $\\mathbf{x} \\in \\mathbf{R}^n$.\n\nThus, a function $f$ is convex, if its Hessian is everywhere positive semi-definite. This allows us to test whether a given function is convex.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}